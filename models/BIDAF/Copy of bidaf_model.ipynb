{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bidaf_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1E8UcRYR1BlmgRH_ipWm2paY2qj-IJ_6Q","authorship_tag":"ABX9TyMsiatT26dqEhvllK6QKWeP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Hvai4UxyMH1S"},"source":["a very good explanation of the BIDAF architecture : \r\n","\r\n","https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b\r\n","\r\n","character embedding with CNN :\r\n","\r\n","https://towardsdatascience.com/besides-word-embedding-why-you-need-to-know-character-embedding-6096a34a3b10\r\n","https://github.com/makcedward/nlp/blob/master/sample/nlp-character_embedding.ipynb"]},{"cell_type":"markdown","metadata":{"id":"AcJDYwmpauq3"},"source":["To run this notebook you should have run the bidaf_preprocessing one.  \r\n","You should as well modify all paths"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8tAi2rmMp_h","executionInfo":{"status":"ok","timestamp":1612707440222,"user_tz":-60,"elapsed":6395,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"1d3aeeba-88b4-42ea-9f4c-8b41b6fdcb2e"},"source":["import tensorflow as tf\r\n","import pandas as pd\r\n","import os\r\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, TimeDistributed, Layer, Softmax, Concatenate, Dropout, Conv1D, GlobalMaxPooling1D\r\n","import tensorflow.keras.backend as K\r\n","from tensorflow.keras.models import Model\r\n","from tqdm import tqdm\r\n","import numpy as np\r\n","import pickle\r\n","import nltk\r\n","import json\r\n","nltk.download('punkt')\r\n","from nltk import word_tokenize\r\n","import gensim.downloader as gloader\r\n","import math\r\n","\r\n","try:\r\n","  from utils.datasets import SQUAD_dataset\r\n","except:\r\n","  import sys\r\n","  sys.path.append(os.path.join(os.getcwd(),'drive/MyDrive/NLP/BIDAF'))\r\n","  from utils.datasets import SQUAD_dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJiZBATwVsHR"},"source":["path_word_tokenizer = os.path.join(os.getcwd(),'drive/MyDrive/NLP/BIDAF/utils', 'tokenizers/word_tokenizer.pkl')\r\n","with open(path_word_tokenizer, 'rb') as handle:\r\n","  tokenizer = pickle.load(handle)\r\n","\r\n","path_char_tokenizer = os.path.join(os.getcwd(), 'drive/MyDrive/NLP/BIDAF/utils', 'tokenizers/char_tokenizer.pkl')\r\n","with open(path_char_tokenizer, 'rb') as char_handle:\r\n","  char_tokenizer = pickle.load(char_handle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNsokDe-Lk6f"},"source":["train_dataset = SQUAD_dataset.from_file('drive/MyDrive/NLP/BIDAF/utils/datasets/train_dataset.pkl')\r\n","valid_dataset = SQUAD_dataset.from_file('drive/MyDrive/NLP/BIDAF/utils/datasets/valid_dataset.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzg9Gv7gMcIe","executionInfo":{"status":"ok","timestamp":1612707462228,"user_tz":-60,"elapsed":28390,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"e558194d-767e-4d79-80f4-4163cd4e1ba1"},"source":["train_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SQUAD_dataset : questions : (10, 25), contexts : (10, 400), char_questions : (10, 25, 15), char_contexts : (10, 400, 15), index : (10, 1)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANbgqwjsMfBK","executionInfo":{"status":"ok","timestamp":1612707462229,"user_tz":-60,"elapsed":28388,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"57154d11-bd0b-425a-a644-b78ae37cb12a"},"source":["print(len(train_dataset))\r\n","len(valid_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6961\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1742"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"68jUK4Q-M8ur"},"source":["# globals variables\r\n","QUESTION_MAXLEN = 25\r\n","CONTEXT_MAXLEN = 400\r\n","EMBEDDING_SIZE = 300 # we can try different embedding size (50, 100, 300) or even try word2vec or fastext instead of glove\r\n","WORD_VOCAB_LEN = len(tokenizer.word_index) + 1 # +1 for the pad token\r\n","BATCH_SIZE = 10\r\n","EPOCHS = 10\r\n","CHAR_VOCAB_LEN = char_tokenizer.num_words # PAD token and UNK token included\r\n","WORD_MAXLEN = 15\r\n","LR = 0.0005\r\n","N_FILTERS = EMBEDDING_SIZE\r\n","FILTER_SIZE = 3\r\n","CHAR_EMBEDDING_SIZE = 8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeQ8obxkV-y1"},"source":["def download_glove_embedding(embedding_dimension = 50):\r\n","\r\n","  \"\"\"\r\n","  download glove model\r\n","  \"\"\"\r\n","\r\n","  download_path = 'glove-wiki-gigaword-{}'.format(embedding_dimension)\r\n","  try:\r\n","    emb_model = gloader.load(download_path)\r\n","  except ValueError as e:\r\n","      print('Glove: 50, 100, 200, 300')\r\n","      raise e\r\n","  return emb_model\r\n","\r\n","def build_embedding_matrix(tokenizer, path_embedding_matrix, glove_model = None):\r\n","\r\n","  \"\"\"\r\n","  build the word embedding matrix based on the glove vocabulary\r\n","  \"\"\"\r\n","\r\n","  if os.path.exists(path_embedding_matrix):\r\n","\r\n","    embedding_matrix = np.load(path_embedding_matrix)\r\n","    return embedding_matrix\r\n","\r\n","  else:\r\n","\r\n","    if glove_model == None:\r\n","      glove_model = download_glove_embedding(EMBEDDING_SIZE)\r\n","\r\n","    embedding_matrix = np.zeros((WORD_VOCAB_LEN, EMBEDDING_SIZE))\r\n","\r\n","    for w,i in tokenizer.word_index.items():\r\n","\r\n","      if w in glove_model.vocab:\r\n","        embedding_matrix[i,:] = glove_model.get_vector(w)\r\n","      else:\r\n","        embedding_matrix[i,:] = np.random.randn(1, EMBEDDING_SIZE)\r\n","\r\n","    del glove_model # we don't need it anymore\r\n","\r\n","    np.save(path_embedding_matrix, embedding_matrix)\r\n","\r\n","    return embedding_matrix\r\n","\r\n","def build_char_embedding_matrix(char_tokenizer):\r\n","\r\n","  \"\"\"\r\n","  build the character embedding matrix\r\n","  \"\"\"\r\n","\r\n","  char_embedding_matrix = np.zeros((CHAR_VOCAB_LEN,CHAR_VOCAB_LEN - 1))  # we have 199 characters that we have to one hot so each character has 199 dimensions\r\n","\r\n","  for char, i in char_tokenizer.word_index.items():\r\n","    if i <= 199:\r\n","      char_embedding_matrix[i][i - 1] = 1\r\n","    else:\r\n","      break\r\n","  return char_embedding_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTL3GYD2TsrV"},"source":["We build the embedding matrix.  \r\n","We can also initialize a char_embedding_matrix, or we can let the model learn these embeddings."]},{"cell_type":"code","metadata":{"id":"4Jkm1-RRXypA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612707648310,"user_tz":-60,"elapsed":214459,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"90873e2a-ae76-429d-ecde-149eba7df740"},"source":["path_embedding_matrix = os.path.join(os.getcwd(), 'drive/MyDrive/NLP/BIDAF/utils/data/embedding.npy')\r\n","embedding_matrix = build_embedding_matrix(tokenizer, path_embedding_matrix)\r\n","\r\n","# instead of one hot encode char tokens maybe we can use glove or randomly fill the matrix\r\n","# these embeddings should be trainable\r\n","# https://github.com/minimaxir/char-embeddings\r\n","#char_embedding_matrix = build_char_embedding_matrix(char_tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[==================================================] 100.0% 376.1/376.1MB downloaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R2rjHEDUTvv4"},"source":["Then we define all layers of our model"]},{"cell_type":"code","metadata":{"id":"00VHMy09YmOp"},"source":["# utils/layers\r\n","class WordEmbedding(Layer):\r\n","    \r\n","    def __init__(self, input_dim, output_dim, input_len, embedding_matrix, trainable = False, mask_zero = True, **kwargs):\r\n","        \r\n","        super(WordEmbedding, self).__init__(**kwargs)\r\n","\r\n","        self.input_dim = input_dim\r\n","        self.output_dim = output_dim\r\n","        self.input_len = input_len\r\n","        self.embedding_matrix = embedding_matrix\r\n","        self.trainable = trainable\r\n","        self.mask_zero = mask_zero\r\n","\r\n","        self.word_embed = Embedding(\r\n","            input_dim = self.input_dim,\r\n","            output_dim = self.output_dim,\r\n","            weights = [self.embedding_matrix],\r\n","            trainable = self.trainable,\r\n","            input_length = self.input_len,\r\n","            mask_zero = self.mask_zero,\r\n","        )\r\n","\r\n","    def build(self, input_shape):\r\n","      self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        input = inputs\r\n","        return self.word_embed(input) \r\n","    \r\n","    # inplement this method in order to get a serializable layer as part of a Functional model\r\n","    def get_config(self):\r\n","        # the base Layer class takes some keywords arguments like name and dtype, it is good to include \r\n","        # them in the config (so we call the parent method and use the update method)\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'input_dim': self.input_dim,\r\n","            'output_dim': self.output_dim,\r\n","            'input_len': self.input_len, \r\n","            'trainable': self.trainable,\r\n","            'mask_zero': self.mask_zero\r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueuhbaJjsYVe"},"source":["# utils/layers\r\n","class CharEmbedding(Layer):\r\n","    \r\n","    def __init__(self, input_dim, output_dim, input_len, **kwargs):\r\n","        \r\n","        super(CharEmbedding, self).__init__(**kwargs)\r\n","\r\n","        self.input_dim = input_dim\r\n","        self.output_dim = output_dim\r\n","        self.input_len = input_len\r\n","        self.char_embed = Embedding(\r\n","            input_dim = self.input_dim, \r\n","            output_dim = self.output_dim,  \r\n","            input_length = self.input_len\r\n","        )\r\n","        # This wrapper allows to apply a layer to every temporal slice of an input.\r\n","        # so we apply the same Embedding to every timestep (index 1) independently\r\n","        self.timed = TimeDistributed(self.char_embed)\r\n","        \r\n","\r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        return self.timed(inputs)\r\n","            \r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'input_dim': self.input_dim,\r\n","            'output_dim': self.output_dim,\r\n","            'input_len': self.input_len, \r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8R7tBTZskqP"},"source":["# utils/layers\r\n","class CharCNN(Layer):\r\n","    \r\n","    def __init__(self, n_filters, filter_width, **kwargs):\r\n","        \r\n","        super(CharCNN, self).__init__(**kwargs)\r\n","        self.n_filters = n_filters\r\n","        self.filter_width = filter_width\r\n","        self.conv = Conv1D(self.n_filters, self.filter_width)\r\n","        self.pool = GlobalMaxPooling1D()\r\n","        self.timed = TimeDistributed(self.pool)\r\n","          \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        return self.timed(self.conv(inputs))\r\n","    \r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'n_filters': self.n_filters,\r\n","            'filter_width': self.filter_width, \r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p36emvbtYtj-"},"source":["# utils/layers\r\n","class HighwayNetwork(Layer):\r\n","    \r\n","    def __init__(self, hidden_size, **kwargs):\r\n","        \r\n","        super(HighwayNetwork, self).__init__(**kwargs)\r\n","        self.hidden_size = hidden_size\r\n","        self.normal = Dense(self.hidden_size, activation = 'relu') \r\n","        self.transform_gate = Dense(self.hidden_size, activation = 'sigmoid')\r\n","        \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):        \r\n","        \r\n","        n = self.normal(inputs)\r\n","        g = self.transform_gate(inputs)\r\n","        x = g*n + (1-g)*inputs \r\n","        return x\r\n","\r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'hidden_size': self.hidden_size, \r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ci1m5TSYvjQ"},"source":["# utils/layers\r\n","class ContextualEmbedding(Layer):\r\n","    \r\n","    def __init__(self, output_dim, **kwargs):\r\n","        \r\n","        super(ContextualEmbedding, self).__init__(**kwargs)\r\n","        self.output_dim = output_dim\r\n","        self.contextual = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n","\r\n","    def build(self, input_shape):\r\n","        self.built = True \r\n","\r\n","    def call(self, inputs):\r\n","        return self.contextual(inputs)\r\n","    \r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'output_dim': self.output_dim,\r\n","        })\r\n","        return config\r\n","    \r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58s56NipY-s-"},"source":["# utils/layers\r\n","class Modelling(Layer):\r\n","    \r\n","    def __init__(self, output_dim, **kwargs):\r\n","        \r\n","        super(Modelling, self).__init__(**kwargs)\r\n","        self.output_dim = output_dim\r\n","        self.modelling1 = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n","        self.modelling2 = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n","        \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        return self.modelling2(self.modelling1(inputs))\r\n","    \r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'output_dim': self.output_dim,\r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPIvap9IZCMS"},"source":["# utils/layers\r\n","class Start(Layer):\r\n","    \r\n","    def __init__(self, **kwargs):\r\n","        \r\n","        super(Start, self).__init__(**kwargs)\r\n","        self.dense = Dense(1, activation = 'linear', use_bias = False)\r\n","        self.dropout = Dropout(0.2)\r\n","        \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        \r\n","        GM = inputs\r\n","        start = self.dense(GM)\r\n","        start = self.dropout(start)\r\n","        p1 = tf.nn.softmax(tf.squeeze(start, axis = 2))\r\n","        return p1\r\n","\r\n","    def get_config(self):\r\n","      \r\n","      config = super().get_config().copy()\r\n","      return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JumPbG69ZEPf"},"source":["# utils/layers\r\n","class ModellingEnd(Layer):\r\n","    \r\n","    def __init__(self, output_dim, **kwargs):\r\n","        \r\n","        super(ModellingEnd, self).__init__(**kwargs)\r\n","        self.output_dim = output_dim\r\n","        self.end = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n","        \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        \r\n","        G, M = inputs\r\n","        M2 = self.end(M)\r\n","        GM2 = tf.concat([G, M2], axis = 2)\r\n","        return GM2\r\n","    \r\n","    def get_config(self):\r\n","\r\n","        config = super().get_config().copy()\r\n","        config.update({\r\n","            'output_dim': self.output_dim,\r\n","        })\r\n","        return config\r\n","\r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4HdLF0UTZGRx"},"source":["# utils/layers\r\n","class End(Layer):\r\n","    \r\n","    def __init__(self, **kwargs):\r\n","        \r\n","        super(End, self).__init__(**kwargs)\r\n","        self.dense = Dense(1, activation = 'linear', use_bias = False)\r\n","        self.dropout = Dropout(0.2)\r\n","        \r\n","    def build(self, input_shape):\r\n","        self.built = True\r\n","\r\n","    def call(self, inputs):\r\n","        \r\n","        GM2 = inputs\r\n","        end = self.dense(GM2)\r\n","        end = self.dropout(end)\r\n","        p2 = tf.nn.softmax(tf.squeeze(end, axis = 2))\r\n","        \r\n","        return p2\r\n","\r\n","\r\n","    def get_config(self):\r\n","\r\n","      config = super().get_config().copy()\r\n","\r\n","      return config\r\n","    \r\n","    @classmethod\r\n","    def from_config(cls, config):\r\n","      return cls(**config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oj0lLdm_FmX"},"source":["# utils/models\r\n","class BIDAF(Model):\r\n","\r\n","  \"\"\"\r\n","  the BIDAF model\r\n","  \"\"\"\r\n","\r\n","  def __init__(self, \r\n","               question_maxlen, \r\n","               context_maxlen, \r\n","               word_vocab_len, \r\n","               embedding_size, \r\n","               embedding_matrix, \r\n","               char_vocab_len,\r\n","               word_maxlen, \r\n","               n_filters, \r\n","               filter_size, \r\n","               char_embedding_size,\r\n","               word_tokenizer_path,\r\n","               char_tokenizer_path,\r\n","               **kwargs):\r\n","    \r\n","    \r\n","    super(BIDAF, self).__init__(name = 'BIDAF', **kwargs)\r\n","\r\n","    self.question_maxlen = question_maxlen\r\n","    self.context_maxlen = context_maxlen\r\n","    self.word_vocab_len = word_vocab_len\r\n","    self.embedding_size = embedding_size\r\n","    self.embedding_matrix = embedding_matrix\r\n","    self.char_vocab_len = char_vocab_len\r\n","    self.char_embedding_size = char_embedding_size\r\n","    self.word_maxlen = word_maxlen\r\n","    self.n_filters = n_filters\r\n","    self.filter_size = filter_size\r\n","\r\n","    with open(word_tokenizer_path, 'rb') as handle:\r\n","      self.word_tokenizer = pickle.load(handle)\r\n","\r\n","    with open(char_tokenizer_path, 'rb') as handle:\r\n","      self.char_tokenizer = pickle.load(handle)\r\n","\r\n","    self.similarity_weights = Dense(1, use_bias = False)\r\n","\r\n","    # layers\r\n","    self.word_embedding = WordEmbedding(self.word_vocab_len, self.embedding_size, self.question_maxlen, self.embedding_matrix)\r\n","    self.char_embedding = CharEmbedding(self.char_vocab_len, self.char_embedding_size, self.word_maxlen)\r\n","    self.cnn = CharCNN(self.n_filters, self.filter_size)\r\n","    self.highway = HighwayNetwork(hidden_size = self.embedding_size + self.n_filters)\r\n","    self.contextual = ContextualEmbedding(self.embedding_size)\r\n","    self.modelling = Modelling(self.embedding_size)\r\n","    self.modelling_end = ModellingEnd(self.embedding_size)\r\n","    self.output_start = Start()\r\n","    self.ouput_end = End()\r\n","\r\n","  def _get_tokens(self):\r\n","\r\n","    self.question = self.word_tokenizer.texts_to_sequences([self._question])\r\n","    self.context = self.word_tokenizer.texts_to_sequences([self._context])\r\n","    self.context_ids = self.context\r\n","\r\n","  def _get_padded_sequences(self):\r\n","\r\n","    self.question = tf.keras.preprocessing.sequence.pad_sequences(self.question, maxlen = self.question_maxlen, padding = 'post', truncating = 'post')\r\n","    self.context = tf.keras.preprocessing.sequence.pad_sequences(self.context, maxlen = self.context_maxlen, padding = 'post', truncating = 'post')\r\n","\r\n","  def make_prediction(self, question, context):\r\n","\r\n","    self._question = word_tokenize(question)\r\n","    self._context = word_tokenize(context)\r\n","\r\n","    self._get_tokens()\r\n","    self._get_padded_sequences()\r\n","\r\n","    self.__get_tokens()\r\n","    self.__get_padded_sequences()\r\n","\r\n","    start, end = self.predict([\r\n","                      self.question,\r\n","                      self.context,\r\n","                      self.question_char,\r\n","                      self.context_char\r\n","                ])\r\n","    \r\n","    start = start.argmax()\r\n","    end = end.argmax() + 1\r\n","\r\n","    if start > end:\r\n","      start = end\r\n","      end = start\r\n","\r\n","    answer = ''\r\n","\r\n","    for i in range(start, end):\r\n","      answer += self.word_tokenizer.index_word[self.context_ids[0][i]] + ' '\r\n","    return answer.strip()\r\n","\r\n","  def multi_predictions(self, datasets, path):\r\n","    predictions = {}\r\n","\r\n","    for dataset in datasets:\r\n","\r\n","      for batch in dataset:\r\n","        sequences = batch[0]\r\n","        labels = batch[1]\r\n","        index = batch[2][0].tolist()\r\n","\r\n","        qw, cw, qc, cc = sequences\r\n","        start, end = labels\r\n","\r\n","        start, end = self.predict([qw, cw, qc, cc])\r\n","\r\n","        start = start.argmax(axis = 1)\r\n","        end = end.argmax(axis = 1)\r\n","\r\n","        answers = []\r\n","\r\n","        for idx, (s, e) in enumerate(zip(start, end)):\r\n","          if s > e:\r\n","            s = e\r\n","            e = s\r\n","\r\n","          answer = ''\r\n","          for i in range(s,e):\r\n","            answer += self.word_tokenizer.index_word[cw[idx][i]] + ' '\r\n","          answers.append(answer.strip())\r\n","        \r\n","        predictions.update({i.strip(): a for i,a in zip(index, answers)})\r\n","    \r\n","    with open(path, 'w') as handle:\r\n","      json.dump(predictions, handle)\r\n","\r\n","    print(f' the file containing the predictions has been creatd in {path}')\r\n","    \r\n","  def __get_tokens(self):\r\n","\r\n","    self.question_char = self.char_tokenizer.texts_to_sequences(self._question)\r\n","    self.context_char = self.char_tokenizer.texts_to_sequences(self._context)\r\n","\r\n","  def __get_padded_sequences(self):\r\n","\r\n","    # pad question at the character level\r\n","    v = tf.keras.preprocessing.sequence.pad_sequences(self.question_char, padding = 'post', truncating = 'post', maxlen = self.word_maxlen)\r\n","    to_add = self.question_maxlen - v.shape[0]\r\n","    add = np.zeros((to_add, self.word_maxlen))\r\n","    arr = np.vstack([v,add])\r\n","    self.question_char = arr\r\n","\r\n","    # pad context at the character level\r\n","    v = tf.keras.preprocessing.sequence.pad_sequences(self.context_char, padding = 'post', truncating = 'post', maxlen = self.word_maxlen)\r\n","    to_add = self.context_maxlen - v.shape[0]\r\n","    add = np.zeros((to_add, self.word_maxlen))\r\n","    arr = np.vstack([v,add])\r\n","    self.context_char = arr\r\n","\r\n","    self.question_char = tf.expand_dims(self.question_char, axis = 0)\r\n","    self.context_char = tf.expand_dims(self.context_char, axis = 0)\r\n","\r\n","\r\n","  def call(self, inputs, training = True):\r\n","    qw, cw, qc, cc = inputs  # (bs, q_len), (bs, ctx_len), (bs, q_len, w_len), (bs, ctx_len, w_len)\r\n","\r\n","    # embedding always non-trainable\r\n","    qw = self.word_embedding(qw) # (bs, q_len, emb)\r\n","    cw = self.word_embedding(cw) # (bs, ctx_len, emb)\r\n","\r\n","    qc = self.char_embedding(qc) # (bs, q_len, w_len, char_emb)\r\n","    cc = self.char_embedding(cc) # (bs, ctx_len, w_len, char_emb)\r\n","\r\n","    qc = self.cnn(qc) # (bs, q_len, n_filters)\r\n","    cc = self.cnn(cc) # (bs, ctx_len, n_filters)\r\n","\r\n","    H = tf.concat([cw, cc], axis = 2) # (bs, ctx_len, emb + n_filters)\r\n","    U = tf.concat([qw, qc], axis = 2) # (bs, q_len, emb + n_filters)\r\n","\r\n","    # highway\r\n","    H = self.highway(H) # (bs, ctx_len, emb + n_filters)\r\n","    U = self.highway(U) # (bs, q_len, emb + n_filters)\r\n","\r\n","    # contextual embedding\r\n","    H = self.contextual(H) # (bs, ctx_len, emb + n_filters)\r\n","    U = self.contextual(U) # (bs, q_len, emb + n_filters)\r\n","\r\n","    # similarity matrix\r\n","    expand_h = tf.concat([[1, 1], [tf.shape(U)[1]], [1]], axis = 0) # [1, 1, q_len, 1]\r\n","    expand_u = tf.concat([[1], [tf.shape(H)[1]], [1, 1]], axis = 0) # [1, ctx_len, 1, 1]\r\n","\r\n","    h = tf.tile(tf.expand_dims(H, axis = 2), expand_h) # (bs, ctx_len, q_len, emb + n_filters)\r\n","    u = tf.tile(tf.expand_dims(U, axis = 1), expand_u) # (bs, ctx_len, q_len, emb + n_filters)\r\n","    h_u = h * u # (bs, ctx_len, q_len, emb + n_filters)\r\n","\r\n","    alpha = tf.concat([h, u, h_u], axis = -1) # (bs, ctx_len, q_len, 3 * (emb + n_filters))\r\n","    \r\n","    similarity_matrix = self.similarity_weights(alpha) # (bs, ctx_len, q_len, 1)\r\n","    similarity_matrix = tf.squeeze(similarity_matrix, 3) # (bs, ctx_len, q_len)\r\n","\r\n","    # context to query attention\r\n","    attention_weights = tf.nn.softmax(similarity_matrix, axis = -1) # (bs, ctx_len, q_len)\r\n","    C2Q = K.batch_dot(attention_weights, U) # (bs, ctx_len, emb + n_filters)\r\n","\r\n","    # query to context attention\r\n","    attention_weights = tf.nn.softmax(tf.math.reduce_max(similarity_matrix, axis = 2), axis = -1) # (bs, ctx_len)\r\n","    attention_weights = tf.expand_dims(attention_weights, axis = 1) # (bs, 1, ctx_len)\r\n","    Q2C = K.batch_dot(attention_weights, H) # (bs, 1, emb + n_filters)\r\n","    Q2C = tf.tile(Q2C, [1, tf.shape(H)[1], 1]) # (bs, ctx_len, emb + n_filters)\r\n","\r\n","    # query aware representation\r\n","    G = tf.concat([H, C2Q, (H * C2Q), (H * Q2C)], axis = 2) # (bs, ctx_len, 4 * (emb + n_filters) )\r\n","\r\n","    # modelling\r\n","    M = self.modelling(G) # (bs, ctx_len, emb + n_filters)\r\n","\r\n","    # output\r\n","    M2 = self.modelling_end([G,M]) # (bs, ctx_len, emb + n_filters)\r\n","\r\n","    # start prediction\r\n","    start = self.output_start(tf.concat([G, M], axis = 2)) # (bs, ctx_len)\r\n","\r\n","    # end prediction\r\n","    end = self.ouput_end(M2) # (bs, ctx_len)\r\n","\r\n","    return start, end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKicRfIW6tUm"},"source":["bidaf_model = BIDAF(\r\n","    QUESTION_MAXLEN,\r\n","    CONTEXT_MAXLEN,\r\n","    WORD_VOCAB_LEN,\r\n","    EMBEDDING_SIZE,\r\n","    embedding_matrix,\r\n","    CHAR_VOCAB_LEN,\r\n","    WORD_MAXLEN,\r\n","    N_FILTERS,\r\n","    FILTER_SIZE,\r\n","    CHAR_EMBEDDING_SIZE,\r\n","    path_word_tokenizer,\r\n","    path_char_tokenizer\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"krJp-At4b0y_"},"source":["loss_function = tf.keras.losses.CategoricalCrossentropy(reduction = 'auto')\r\n","optimizer = tf.keras.optimizers.Nadam(learning_rate = LR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kg2EI6tBcbB8"},"source":["# https://udai.gitbook.io/practical-ml/nn/training-and-debugging-of-nn <- useful blog about machine learning / deep learning\r\n","# steps to be performed in each training step\r\n","@tf.function\r\n","def train_step(model, input_vector, output_vector, loss_fn):\r\n","    with tf.GradientTape() as tape:\r\n","        # forward propagation\r\n","        output_predicted = model(input_vector, training = True)\r\n","        # loss\r\n","        loss_start = loss_function(output_vector[0], output_predicted[0])\r\n","        loss_end = loss_function(output_vector[1], output_predicted[1])\r\n","        loss_final = loss_start + loss_end\r\n","    # getting gradients\r\n","    gradients = tape.gradient(loss_final, model.trainable_variables)\r\n","    # applying gradients\r\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n","    return loss_start, loss_end, output_predicted, gradients"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTNI3WKaciDu"},"source":["# https://udai.gitbook.io/practical-ml/nn/training-and-debugging-of-nn\r\n","# steps to be performed in each validation step\r\n","@tf.function\r\n","def val_step(model, input_vector, output_vector, loss_fn):\r\n","    # getting output of validation data\r\n","    output_predicted = model(input_vector, training = False)\r\n","    # loss calculation\r\n","    loss_start = loss_function(output_vector[0], output_predicted[0])\r\n","    loss_end = loss_function(output_vector[1], output_predicted[1])\r\n","    return loss_start, loss_end, output_predicted"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6on5ZTXwZING"},"source":["def f1_score(y_true, y_pred):    # taken from old keras source code\r\n","    \r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    \r\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","    \r\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","    \r\n","    precision = true_positives / (predicted_positives + K.epsilon())\r\n","    recall = true_positives / (possible_positives + K.epsilon())\r\n","    \r\n","    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\r\n","    \r\n","    return f1_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmKsimsMcoHu"},"source":["# defining functions to compute the mean loss for each epoch\r\n","train_start_loss = tf.keras.metrics.Mean(name = 'train_start_loss')\r\n","train_end_loss = tf.keras.metrics.Mean(name = 'train_end_loss')\r\n","val_start_loss = tf.keras.metrics.Mean(name = 'val_start_loss')\r\n","val_end_loss = tf.keras.metrics.Mean(name = 'val_end_loss')\r\n","train_start_f1 = tf.keras.metrics.Mean(name = 'train_start_f1')\r\n","train_end_f1 = tf.keras.metrics.Mean(name = 'train_end_f1')\r\n","val_start_f1 = tf.keras.metrics.Mean(name = 'val_start_f1')\r\n","val_end_f1 = tf.keras.metrics.Mean(name = 'val_end_f1')\r\n","train_start_acc = tf.keras.metrics.CategoricalAccuracy(name = 'train_start_acc')\r\n","train_end_acc = tf.keras.metrics.CategoricalAccuracy(name = 'train_end_acc')\r\n","val_start_acc = tf.keras.metrics.CategoricalAccuracy(name = 'val_start_acc')\r\n","val_end_acc = tf.keras.metrics.CategoricalAccuracy(name = 'val_end_acc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qp9ojYdzUzwG"},"source":["best_loss = 100 # we initialize a loss value for model checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGoXLG59p5Jy","executionInfo":{"status":"ok","timestamp":1612707655855,"user_tz":-60,"elapsed":221953,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"ba01e109-27a9-493c-f7fc-658a2d952c1c"},"source":["# don't run the next cell if your model is already trained\r\n","# don't run this cell if your model need to be trained but run the next one\r\n","bidaf_model.load_weights('drive/MyDrive/NLP/BIDAF/utils/models/weights/bidaf_weights')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9b4aedd5c0>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"5fOKYFlzcwiW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612378731447,"user_tz":-60,"elapsed":1118021,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"ed14ba82-a7b2-44f9-dad4-e558bfa8526c"},"source":["for epoch in range(EPOCHS):\r\n","    \r\n","    # resetting the states of the loss and metrics\r\n","    train_start_loss.reset_states()\r\n","    train_end_loss.reset_states()\r\n","    val_start_loss.reset_states()\r\n","    val_end_loss.reset_states()\r\n","    train_start_f1.reset_states()\r\n","    train_end_f1.reset_states()\r\n","    val_start_f1.reset_states()\r\n","    val_end_f1.reset_states()\r\n","    train_start_acc.reset_states()\r\n","    train_end_acc.reset_states()\r\n","    val_start_acc.reset_states()\r\n","    val_end_acc.reset_states()\r\n","    \r\n","    # iterating over train data batch by batch\r\n","    for text_seq, label_seq, _ in tqdm(iterable = train_dataset, total = len(train_dataset)):\r\n","        # train step\r\n","        loss_start_, loss_end_, pred_out, gradients = train_step(bidaf_model, text_seq, label_seq, loss_function)\r\n","        # adding loss to train loss\r\n","        train_start_loss(loss_start_)\r\n","        train_end_loss(loss_end_)\r\n","        \r\n","        # calculating f1 for batch\r\n","        f1_start = f1_score(label_seq[0], pred_out[0])\r\n","        f1_end = f1_score(label_seq[1], pred_out[1])\r\n","        train_start_f1(f1_start)\r\n","        train_end_f1(f1_end)\r\n","        train_start_acc(label_seq[0], pred_out[0])\r\n","        train_end_acc(label_seq[1], pred_out[1])\r\n","    \r\n","    # validation data\r\n","    for text_seq_val, label_seq_val, _ in valid_dataset:\r\n","        # getting val output\r\n","        loss_val_start, loss_val_end, pred_out_val = val_step(bidaf_model, text_seq_val, label_seq_val, loss_function)\r\n","        \r\n","        val_start_loss(loss_val_start)\r\n","        val_end_loss(loss_val_end)\r\n","        \r\n","        # calculating metric\r\n","        f1_start_val = f1_score(label_seq_val[0], pred_out_val[0])\r\n","        f1_end_val = f1_score(label_seq_val[1], pred_out_val[1])\r\n","        val_start_f1(f1_start_val)\r\n","        val_end_f1(f1_end_val)\r\n","        val_start_acc(label_seq_val[0], pred_out_val[0])\r\n","        val_end_acc(label_seq_val[1], pred_out_val[1])\r\n","    \r\n","   \r\n","    # printing\r\n","    template = '''Epoch {}, Train Start Loss: {:0.6f}, Train Start Acc : {:0.5f}, Start F1 Score: {:0.5f}, Train End Loss: {:0.6f}, Train End Acc : {:0.5f}, End F1 Score: {:0.5f},\r\n","    Val Start Loss: {:0.6f}, Val Start Acc : {:0.5f}, Val Start F1 Score: {:0.5f}, Val End Loss: {:0.6f}, Val End Acc : {:0.5f}, Val End F1 Score: {:0.5f}'''\r\n","\r\n","    print(template.format(epoch + 1, train_start_loss.result(), train_start_acc.result(), train_start_f1.result(), \r\n","                          train_end_loss.result(), train_end_acc.result(), train_end_f1.result(),\r\n","                          val_start_loss.result(), val_start_acc.result(), val_start_f1.result(),\r\n","                          val_end_loss.result(), val_end_acc.result(), val_end_f1.result()))\r\n","\r\n","\r\n","    if (val_start_loss.result() + val_end_loss.result()) < best_loss:\r\n","      print('Saving weights...')\r\n","      bidaf_model.save_weights('drive/MyDrive/NLP/BIDAF/utils/models/weights/bidaf_weights')\r\n","      print('\\n Done !')\r\n","      best_loss = (val_start_loss.result() + val_end_loss.result())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:48<00:00,  2.59it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1, Train Start Loss: 3.713853, Train Start Acc : 0.21268, Start F1 Score: 0.09921, Train End Loss: 3.516613, Train End Acc : 0.23350, End F1 Score: 0.11051,\n","    Val Start Loss: 2.201488, Val Start Acc : 0.44312, Val Start F1 Score: 0.28122, Val End Loss: 1.988928, Val End Acc : 0.47941, Val End F1 Score: 0.32824\n","Saving weights...\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," Done !\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:16<00:00,  2.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2, Train Start Loss: 2.672784, Train Start Acc : 0.42808, Start F1 Score: 0.37917, Train End Loss: 2.524039, Train End Acc : 0.45798, End F1 Score: 0.42111,\n","    Val Start Loss: 1.754525, Val Start Acc : 0.53219, Val Start F1 Score: 0.45609, Val End Loss: 1.582747, Val End Acc : 0.57153, Val End F1 Score: 0.50670\n","Saving weights...\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," Done !\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3, Train Start Loss: 2.402298, Train Start Acc : 0.48576, Start F1 Score: 0.46137, Train End Loss: 2.250612, Train End Acc : 0.51869, End F1 Score: 0.50846,\n","    Val Start Loss: 1.659768, Val Start Acc : 0.55321, Val Start F1 Score: 0.51884, Val End Loss: 1.506444, Val End Acc : 0.58600, Val End F1 Score: 0.55114\n","Saving weights...\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," Done !\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:18<00:00,  2.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4, Train Start Loss: 2.203818, Train Start Acc : 0.52497, Start F1 Score: 0.51792, Train End Loss: 2.074208, Train End Acc : 0.55607, End F1 Score: 0.56182,\n","    Val Start Loss: 1.655275, Val Start Acc : 0.55401, Val Start F1 Score: 0.53658, Val End Loss: 1.502723, Val End Acc : 0.59065, Val End F1 Score: 0.57162\n","Saving weights...\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," Done !\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n","  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 5, Train Start Loss: 2.055331, Train Start Acc : 0.55568, Start F1 Score: 0.55691, Train End Loss: 1.939746, Train End Acc : 0.58337, End F1 Score: 0.60004,\n","    Val Start Loss: 1.702703, Val Start Acc : 0.55619, Val Start F1 Score: 0.54585, Val End Loss: 1.561018, Val End Acc : 0.59255, Val End F1 Score: 0.58075\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:28<00:00,  2.61it/s]\n","  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 6, Train Start Loss: 1.918788, Train Start Acc : 0.58545, Start F1 Score: 0.59501, Train End Loss: 1.813458, Train End Acc : 0.60949, End F1 Score: 0.63124,\n","    Val Start Loss: 1.731502, Val Start Acc : 0.55321, Val Start F1 Score: 0.55223, Val End Loss: 1.629714, Val End Acc : 0.58950, Val End F1 Score: 0.59012\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n","  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 7, Train Start Loss: 1.824023, Train Start Acc : 0.60426, Start F1 Score: 0.61978, Train End Loss: 1.720178, Train End Acc : 0.62920, End F1 Score: 0.65666,\n","    Val Start Loss: 1.750128, Val Start Acc : 0.54965, Val Start F1 Score: 0.54725, Val End Loss: 1.641849, Val End Acc : 0.59203, Val End F1 Score: 0.59088\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:30<00:00,  2.61it/s]\n","  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 8, Train Start Loss: 1.731592, Train Start Acc : 0.62444, Start F1 Score: 0.64413, Train End Loss: 1.646126, Train End Acc : 0.64408, End F1 Score: 0.67681,\n","    Val Start Loss: 1.887377, Val Start Acc : 0.54574, Val Start F1 Score: 0.55190, Val End Loss: 1.752178, Val End Acc : 0.58428, Val End F1 Score: 0.59076\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:26<00:00,  2.61it/s]\n","  0%|          | 0/6961 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 9, Train Start Loss: 1.646621, Train Start Acc : 0.64293, Start F1 Score: 0.66637, Train End Loss: 1.578775, Train End Acc : 0.65967, End F1 Score: 0.69311,\n","    Val Start Loss: 1.933540, Val Start Acc : 0.53948, Val Start F1 Score: 0.54766, Val End Loss: 1.834540, Val End Acc : 0.57905, Val End F1 Score: 0.58306\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6961/6961 [44:29<00:00,  2.61it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 10, Train Start Loss: 1.597884, Train Start Acc : 0.65529, Start F1 Score: 0.68230, Train End Loss: 1.528513, Train End Acc : 0.66967, End F1 Score: 0.70666,\n","    Val Start Loss: 1.975476, Val Start Acc : 0.54396, Val Start F1 Score: 0.54932, Val End Loss: 1.815104, Val End Acc : 0.58163, Val End F1 Score: 0.58247\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wygC27fedajx"},"source":["def print_predictions(batch):\r\n","\r\n","  \"\"\"\r\n","  utility function to visualize some predictions\r\n","  \"\"\"\r\n","\r\n","  idx = np.random.randint(BATCH_SIZE)\r\n","  samples = valid_dataset[batch]\r\n","\r\n","  sequences, labels, _ = samples\r\n","\r\n","  qw = sequences[0][idx]\r\n","  cw = sequences[1][idx]\r\n","  qc = sequences[2][idx]\r\n","  cc = sequences[3][idx]\r\n","\r\n","  real_start = labels[0][idx]\r\n","  real_end = labels[1][idx]\r\n","\r\n","  \"\"\"\r\n","  Function that takes record numbers as input and predicts the answer for that record\r\n","  \"\"\"\r\n","\r\n","  print('Question:')\r\n","  for i in qw:\r\n","    if i == 0:\r\n","      break\r\n","    else:\r\n","      print(tokenizer.index_word[i], end = ' ')\r\n","\r\n","  print('\\nContext:')\r\n","  for i in cw:\r\n","    if i == 0:\r\n","      break\r\n","    else:\r\n","      print(tokenizer.index_word[i], end = ' ')\r\n","      \r\n","  print('\\nPredicted Answer:')\r\n","  _qw = qw.reshape(1, qw.shape[0])\r\n","  _cw = cw.reshape(1, cw.shape[0])\r\n","  _qc = np.expand_dims(qc, axis = 0)\r\n","  _cc = np.expand_dims(cc, axis = 0)\r\n","  start, end = bidaf_model.predict((_qw, _cw, _qc, _cc))\r\n","  start = start.argmax()\r\n","  end = end.argmax() + 1\r\n","\r\n","  if start > end:\r\n","    start = end\r\n","    end = start\r\n","\r\n","  for i in range(start, end ):\r\n","    print(tokenizer.index_word[cw[i]], end = ' ')\r\n","  print('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TOn5DDbddfq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612707689440,"user_tz":-60,"elapsed":18546,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"a33d53a6-c9b2-46c7-a7f8-19f8479908d1"},"source":["data_points = [8,15,52,152,332]\r\n","for i in data_points:\r\n","  print_predictions(i)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Question:\n","what type of system is american federalism ? \n","Context:\n","federal law and treaties , so long as they are in accordance with the constitution , preempt conflicting state and territorial laws in the 50 u.s. states and in the territories . however , the scope of federal preemption is limited because the scope of federal power is not universal . in the dual-sovereign system of american federalism ( actually tripartite because of the presence of indian reservations ) , states are the plenary sovereigns , each with their own constitution , while the federal sovereign possesses only the limited supreme authority enumerated in the constitution . indeed , states may grant their citizens broader rights than the federal constitution as long as they do not infringe on any federal constitutional rights . thus , most u.s. law ( especially the actual `` living law '' of contract , tort , property , criminal , and family law experienced by the majority of citizens on a day-to-day basis ) consists primarily of state law , which can and does vary greatly from one state to the next . \n","Predicted Answer:\n","dual-sovereign system \n","\n","Question:\n","what did this menace undermine ? \n","Context:\n","after the first world war , however , it became apparent that the number of mixed-race people was growing at a faster rate than the white population , and by 1930 fear of the `` half-caste menace '' undermining the white australia ideal from within was being taken as a serious concern . dr. cecil cook , the northern territory protector of natives , noted that : \n","Predicted Answer:\n","the white australia ideal from within was being taken as a serious concern . \n","\n","Question:\n","name three painters ? \n","Context:\n","yet the most impressive aesthetic works were done among the scholars and urban elite . calligraphy and painting remained a central interest to both court painters and scholar-gentry who considered the four arts part of their cultural identity and social standing . the painting of the early years of the dynasty included such painters as the orthodox four wangs and the individualists bada shanren ( 1626–1705 ) and shitao ( 1641–1707 ) . the nineteenth century saw such innovations as the shanghai school and the lingnan school which used the technical skills of tradition to set the stage for modern painting . \n","Predicted Answer:\n","orthodox four wangs and the individualists bada shanren ( \n","\n","Question:\n","what style architecture is the westminster abbey considered ? \n","Context:\n","westminster abbey , formally titled the collegiate church of st peter at westminster , is a large , mainly gothic abbey church in the city of westminster , london , located just to the west of the palace of westminster . it is one of the most notable religious buildings in the united kingdom and has been the traditional place of coronation and burial site for english and , later , british monarchs . between 1540 and 1556 the abbey had the status of a cathedral . since 1560 , however , the building is no longer an abbey nor a cathedral , having instead the status of a church of england `` royal peculiar '' —a church responsible directly to the sovereign . the building itself is the original abbey church . \n","Predicted Answer:\n","gothic abbey \n","\n","Question:\n","what effect has the issue of indigenous autonomy had on bolivia ? \n","Context:\n","morales began work on his `` indigenous autonomy '' policy , which he launched in the eastern lowlands department on august 3 , 2009 , making bolivia the first country in the history of south america to affirm the right of indigenous people to govern themselves . speaking in santa cruz department , the president called it `` a historic day for the peasant and indigenous movement '' , saying that , though he might make errors , he would `` never betray the fight started by our ancestors and the fight of the bolivian people '' . a vote on further autonomy will take place in referendums which are expected to be held in december 2009. the issue has divided the country . \n","Predicted Answer:\n","a vote on further autonomy will take place in referendums which \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E3IzPCNqEO0j"},"source":["question = 'In what country is Normandy located?'\r\n","context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"DlbVjaSzbXH4","executionInfo":{"status":"ok","timestamp":1612707697876,"user_tz":-60,"elapsed":3511,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"d017e4a2-ade5-48c2-f7f5-edfe5fba5340"},"source":["bidaf_model.make_prediction(question,context)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'france .'"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5yHWVgHzBA9","executionInfo":{"status":"ok","timestamp":1612708013076,"user_tz":-60,"elapsed":303771,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"304b8044-c3d3-4230-f227-c2700b6b0e6f"},"source":["path_save_validation = os.path.join(os.getcwd(),'drive/MyDrive/NLP/BIDAF/utils', 'data/predictions.json')\r\n","bidaf_model.multi_predictions([valid_dataset], path_save_validation)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" the file containing the predictions has been creatd in /content/drive/MyDrive/NLP/BIDAF/utils/data/predictions.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saD8cnRcA6tR","executionInfo":{"status":"ok","timestamp":1612708065696,"user_tz":-60,"elapsed":3953,"user":{"displayName":"corentin magyar","photoUrl":"","userId":"04135457892709862388"}},"outputId":"dd48acc3-8dfa-4d56-d22a-5a110af414ae"},"source":["# the evaluate.py file can be downloaded on the SQUAD website https://rajpurkar.github.io/SQuAD-explorer/\r\n","!python3 drive/MyDrive/NLP/BIDAF/utils/data/evaluate.py drive/MyDrive/NLP/BIDAF/utils/data/valid_set.json drive/MyDrive/NLP/BIDAF/utils/data/predictions.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\n","  \"exact\": 51.02509619249986,\n","  \"f1\": 65.79343949729639,\n","  \"total\": 17413,\n","  \"HasAns_exact\": 51.02509619249986,\n","  \"HasAns_f1\": 65.79343949729639,\n","  \"HasAns_total\": 17413\n","}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F9Sxh-VBWXOj"},"source":["**FURTHER WORK**:\r\n","* try with GRU instead of LSTM (GRU are usually faster)\r\n","* make batches with different padding size (so far, `CONTEXT_MAXLEN`, `WORD_MAXLEN` and `QUESTION_MAXLEN` are the same for each batch, while we could create local variables for each batch )\r\n","* try others models (QANet, BERT,  Multi-Perspective Context Matching, ... )"]}]}