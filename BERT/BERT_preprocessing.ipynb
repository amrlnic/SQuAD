{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrXpyz2vZhs1"
      },
      "source": [
        "In order to run this notebook, the first things you should do are :\r\n",
        "* pip install pandas numpy tensorflow nltk gensim sklearn\r\n",
        "* modify the `SQUAD_DIR` variable (path to squad file)\r\n",
        "* modify all others paths (where to save datasets, tokenizers...)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uIC_dIFytkR",
        "outputId": "64938351-bad2-45dd-df52-1d8146dd3437"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hETK3Axg43yB",
        "outputId": "dd51f20b-9a2b-41e3-c366-081244f41c98"
      },
      "source": [
        "import json\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import nltk\r\n",
        "from nltk import word_tokenize\r\n",
        "nltk.download('punkt')\r\n",
        "import gensim.downloader as gloader\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import re\r\n",
        "import pickle\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqLS5R574tdD"
      },
      "source": [
        "EMBEDDING_SIZE = 300\r\n",
        "\r\n",
        "def download_glove_model(embedding_dimension = 50):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  download glove model\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\r\n",
        "  try:\r\n",
        "    print('[INFO] downloading glove {}'.format(embedding_dimension))\r\n",
        "    emb_model = gloader.load(download_path)\r\n",
        "    print('[INFO] done !')\r\n",
        "  except ValueError as e:\r\n",
        "      print(\"Glove: 50, 100, 200, 300\")\r\n",
        "      raise e\r\n",
        "  return emb_model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0jaIxPTLmxH",
        "outputId": "5a579731-d531-4436-fbde-145ed7e7cd99"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re, json, requests\r\n",
        "import io\r\n",
        "\r\n",
        "url = \"https://raw.githubusercontent.com/amrlnic/SQuAD/main/data/training_set.json\" # Make sure the url is the raw version of the file on GitHub\r\n",
        "download = requests.get(url).content\r\n",
        "data = json.loads(download)\r\n",
        "\r\n",
        "def load_dataset(file, record_path = ['data', 'paragraphs', 'qas', 'answers'], verbose = True):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the SQUAD dataset into a dataframe\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"Reading the json file\")\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"[INFO] processing...\")\r\n",
        "\r\n",
        "  # parsing different level's in the json file\r\n",
        "  js = pd.json_normalize(file , record_path )\r\n",
        "  m = pd.json_normalize(file, record_path[:-1] )\r\n",
        "  r = pd.json_normalize(file, record_path[:-2])\r\n",
        "  t = pd.json_normalize(file, record_path[0])\r\n",
        "\r\n",
        "  title = pd.json_normalize(file['data'], record_path = ['paragraphs'], meta = 'title')\r\n",
        "\r\n",
        "  #combining it into single dataframe\r\n",
        "  idx = np.repeat(r['context'].values, r.qas.str.len())\r\n",
        "  ndx  = np.repeat(m['id'].values, m['answers'].str.len())\r\n",
        "  m['context'] = idx\r\n",
        "  m['title'] = np.repeat(title['title'].values, r.qas.str.len())\r\n",
        "  js['q_idx'] = ndx\r\n",
        "  main = pd.concat([ m[['id','question','context', 'title']].set_index('id'), js.set_index('q_idx')], 1, sort = False).reset_index()\r\n",
        "  main['c_id'] = main['context'].factorize()[0]\r\n",
        "  if verbose:\r\n",
        "      print(f\"[INFO] there are {main.shape[0]} questions with single answer\")\r\n",
        "      print(f\"[INFO] there are {main.groupby('c_id').sum().shape[0]} different contexts\")\r\n",
        "      print(f\"[INFO] there are {len(t)} unrelated subjects\")\r\n",
        "      print(\"[INFO] Done\")\r\n",
        "  return main\r\n",
        "\r\n",
        "squad_dataset = load_dataset(data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the json file\n",
            "[INFO] processing...\n",
            "[INFO] there are 87599 questions with single answer\n",
            "[INFO] there are 18891 different contexts\n",
            "[INFO] there are 442 unrelated subjects\n",
            "[INFO] Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "lzHPUWA45dzO",
        "outputId": "4b5c0adb-a2b6-46ce-bcc5-5860d02be8ef"
      },
      "source": [
        "squad_dataset.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>188</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ... c_id\n",
              "0  5733be284776f41900661182  ...    0\n",
              "1  5733be284776f4190066117f  ...    0\n",
              "2  5733be284776f41900661180  ...    0\n",
              "3  5733be284776f41900661181  ...    0\n",
              "4  5733be284776f4190066117e  ...    0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCWKKV2RAhML"
      },
      "source": [
        "SAMPLES = squad_dataset.shape[0]\r\n",
        "\r\n",
        "def preprocess_sentence(text):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  lowercase and strip the given text\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  text = text.lower()\r\n",
        "  text = text.strip()\r\n",
        "  return text\r\n",
        "\r\n",
        "def clean_dataset(dataset):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  preprocess the dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  _dataset = dataset.copy()\r\n",
        "\r\n",
        "  cleaned_questions = _dataset['question'].apply(preprocess_sentence)\r\n",
        "  cleaned_texts = _dataset['text'].apply(preprocess_sentence)\r\n",
        "\r\n",
        "  # we process only different contexts and then we duplicate them\r\n",
        "  unique_context = pd.Series(_dataset['context'].unique())\r\n",
        "  count_c = _dataset.groupby('c_id').count()['text']\r\n",
        "  cleaned_contexts = unique_context.apply(preprocess_sentence)\r\n",
        "\r\n",
        "  _dataset['question'] = cleaned_questions\r\n",
        "  _dataset['text'] = cleaned_texts\r\n",
        "  _dataset['context'] = pd.Series(np.repeat(cleaned_contexts, count_c).tolist())\r\n",
        "\r\n",
        "  return _dataset"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSVZ45xxqqqz"
      },
      "source": [
        "squad_dataset = clean_dataset(squad_dataset)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq8B58osDLvX"
      },
      "source": [
        "def get_tokenizer(dataset, glove_model = None):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  create the word and char tokenizer and feed them \r\n",
        "  on the given dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = 'UNK', filters = '')\r\n",
        "\r\n",
        "  # we will only keep the 200 - 1 most frequent characters (otherwise oom issue)\r\n",
        "  # others tokens are replaced by UNK token \r\n",
        "  # we keep 199 most frequent tokens and indice 1 is UNK token (so we keep 198 tokens)\r\n",
        "  char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level = True, filters = '', oov_token = 'UNK', num_words = 200)\r\n",
        "\r\n",
        "  if glove_model == None:\r\n",
        "    glove_model = download_glove_model(EMBEDDING_SIZE)\r\n",
        "\r\n",
        "  tokenized_questions = dataset['question'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  contexts = pd.Series(dataset['context'].unique())\r\n",
        "  tokenized_contexts = contexts.apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  sequences = glove_model.index2entity + tokenized_questions + tokenized_contexts\r\n",
        "\r\n",
        "  del glove_model # we  don't need anymore the glove model\r\n",
        "\r\n",
        "  tokenizer.fit_on_texts(sequences)\r\n",
        "  char_tokenizer.fit_on_texts(dataset['question'].to_list() + contexts.to_list())\r\n",
        "\r\n",
        "  return tokenizer, char_tokenizer\r\n",
        "\r\n",
        "\r\n",
        "def update_tokenizer(dataset, tokenizer, char_tokenizer):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  update the existing word/char vocabulary on a new dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  tokenized_questions = dataset['question'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  contexts = pd.Series(dataset['context'].unique())\r\n",
        "  tokenized_contexts = contexts.apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  sequences = tokenized_questions + tokenized_contexts\r\n",
        "  tokenizer.fit_on_texts(sequences)\r\n",
        "\r\n",
        "  char_tokenizer.fit_on_texts(dataset['question'].to_list() + contexts.to_list())\r\n",
        "\r\n",
        "def get_start_end(row):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  get the start and end span for each sample,\r\n",
        "  if the span cannot be found return -1\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  context = row['context']\r\n",
        "  answer = row['text']\r\n",
        "  tok_answer = word_tokenize(answer)\r\n",
        "\r\n",
        "  _start = context.find(answer)\r\n",
        "\r\n",
        "  if _start == -1:\r\n",
        "    # the answer is not in the context\r\n",
        "    # maybe due to a typo\r\n",
        "    row['start'] = -1\r\n",
        "    row['end'] = -1\r\n",
        "    return row\r\n",
        "\r\n",
        "  lc = context[:_start]\r\n",
        "  lc = word_tokenize(lc)\r\n",
        "\r\n",
        "  start = len(lc)\r\n",
        "  end = start + len(tok_answer)\r\n",
        "\r\n",
        "  row['start'] = start\r\n",
        "  row['end'] = end\r\n",
        "\r\n",
        "  return row\r\n",
        "\r\n",
        "def tokenize(dataset, tokenizer, char_tokenizer):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  tokenize the given dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  _dataset = dataset.copy()\r\n",
        "\r\n",
        "  tokenized_questions = _dataset['question'].apply(word_tokenize).to_list()\r\n",
        "  tokenized_contexts = _dataset['context'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  t_q = tokenizer.texts_to_sequences(tokenized_questions)\r\n",
        "  t_c = tokenizer.texts_to_sequences(tokenized_contexts)\r\n",
        "\r\n",
        "  c_q = []\r\n",
        "  c_c = []\r\n",
        "\r\n",
        "  for question, context in zip(tokenized_questions, tokenized_contexts):\r\n",
        "    _q = char_tokenizer.texts_to_sequences(question)\r\n",
        "    _c = char_tokenizer.texts_to_sequences(context)\r\n",
        "    c_q.append(_q)\r\n",
        "    c_c.append(_c)\r\n",
        "\r\n",
        "  _dataset['tokenized_question'] = t_q\r\n",
        "  _dataset['tokenized_context'] = t_c\r\n",
        "\r\n",
        "  _dataset['char_tokenized_question'] = c_q\r\n",
        "  _dataset['char_tokenized_context'] = c_c\r\n",
        "\r\n",
        "  return _dataset\r\n",
        "\r\n",
        "def split(dataset, test_size = 0.2, random_state = 42):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  split the dataset in two part: the training and the validation\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # random_state for deterministic state\r\n",
        "  tr, vl = train_test_split(dataset, test_size = test_size, random_state = random_state)\r\n",
        "  tr.reset_index(drop = True, inplace = True)\r\n",
        "  vl.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  return tr,vl\r\n",
        "\r\n",
        "def df_to_json(df, path):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the given dataframe into the SQUAD json format\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  data = []\r\n",
        "\r\n",
        "  for title, articles in df.groupby('title'):\r\n",
        "    chapter = {'title': title}\r\n",
        "    paragraphs = []\r\n",
        "    for context, contents in articles.groupby('context'):\r\n",
        "      paragraph = {'context': context}\r\n",
        "      qas = []\r\n",
        "      for i, content in contents.iterrows():\r\n",
        "        qa = {'answers': [{'answer_start': content['answer_start'], 'text': content['text']}], 'question': content['question'], 'id': content['index']}\r\n",
        "        qas.append(qa)\r\n",
        "      paragraph.update({'qas': qas})\r\n",
        "      paragraphs.append(paragraph)\r\n",
        "    chapter.update({'paragraphs': paragraphs})\r\n",
        "    data.append(chapter)\r\n",
        "  raw_data = {'data': data}\r\n",
        "\r\n",
        "  with open(path, 'w') as handle:\r\n",
        "    json.dump(raw_data, handle)\r\n",
        "\r\n",
        "  print(f'dataset saved in {path}')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8pXuOXlpLsx"
      },
      "source": [
        "tr_df, vl_df = split(squad_dataset)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGk_DpS3RS32",
        "outputId": "0e34320d-f49c-4fed-f382-319d2f6dd367"
      },
      "source": [
        "tr_df.shape[0],vl_df.shape[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70079, 17520)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0VbHyp4YSUx"
      },
      "source": [
        "Our vocabulary is based on the Glove vocabulary, and we add terms from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hY8Z7HQFKjo",
        "outputId": "2c77c263-1cd0-44de-d118-c4a154cf3fa8"
      },
      "source": [
        "tokenizer, char_tokenizer = get_tokenizer(tr_df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] downloading glove 300\n",
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n",
            "[INFO] done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILsFqw2bKf5L",
        "outputId": "9ef6bc07-2d21-4e4f-d7f3-8fe05e24402a"
      },
      "source": [
        "print(len(tokenizer.word_index))\r\n",
        "len(char_tokenizer.word_index)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "429064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWoZPgxdYbkz"
      },
      "source": [
        "We then update our vocabulary with terms from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzv_ZS3Zqifn"
      },
      "source": [
        "update_tokenizer(vl_df, tokenizer, char_tokenizer)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLwNWJsorIae",
        "outputId": "cd49d6f2-1928-47d6-e64d-4b0959bb473b"
      },
      "source": [
        "print(len(tokenizer.word_index))\r\n",
        "len(char_tokenizer.word_index)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "429758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM8oYX_SHkni"
      },
      "source": [
        "# take a while\r\n",
        "tr_df = tr_df.apply(get_start_end, axis = 1)\r\n",
        "vl_df = vl_df.apply(get_start_end, axis = 1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox1J7Z8YhVcv"
      },
      "source": [
        "we get rid of samples where the answer doesn't match the context (maybe there is a typo in the answer or the context).  \r\n",
        "To avoid to discard many samples, we could lemmatize / stem the text.   \r\n",
        "Obviously, lemmatization is a better choice for our task, but if we want a really accurate lemmatization processing, we need to do POS tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eTsENy6jU-t",
        "outputId": "790b03c1-9df6-4ec2-f2f9-0533c246709b"
      },
      "source": [
        "tr_df[tr_df['start'] == -1].shape[0], vl_df[vl_df['start'] == -1].shape[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "RfAls7CF683U",
        "outputId": "8bdd7816-37d6-4f4f-ae14-ed90e84556b8"
      },
      "source": [
        "tr_df[tr_df['start'] == -1]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>56de31984396321400ee2672</td>\n",
              "      <td>on what date was the 2013 human development re...</td>\n",
              "      <td>some countries were not included for various r...</td>\n",
              "      <td>Human_Development_Index</td>\n",
              "      <td>92</td>\n",
              "      <td>march 14, 2013</td>\n",
              "      <td>2185</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>56e17f5de3433e1400422f8c</td>\n",
              "      <td>what field studies the placement of catalan in...</td>\n",
              "      <td>in central catalan, unstressed vowels reduce t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>0</td>\n",
              "      <td>catalan sociolinguistics</td>\n",
              "      <td>3470</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3983</th>\n",
              "      <td>56e1b97fcd28a01900c67ad8</td>\n",
              "      <td>what is the official regulating body of  valen...</td>\n",
              "      <td>valencian is classified as a western dialect, ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>168</td>\n",
              "      <td>the valencian academy of language</td>\n",
              "      <td>3488</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6198</th>\n",
              "      <td>56e1b4decd28a01900c67a91</td>\n",
              "      <td>what language is the regulator meant to standa...</td>\n",
              "      <td>in alghero, the iec has adapted its standard t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>103</td>\n",
              "      <td>catalan</td>\n",
              "      <td>3486</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6994</th>\n",
              "      <td>56e1b738cd28a01900c67aae</td>\n",
              "      <td>where are the provinces of lleida and tarragona?</td>\n",
              "      <td>in 2011, the aragonese government passed a dec...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>94</td>\n",
              "      <td>western catalonia</td>\n",
              "      <td>3487</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66889</th>\n",
              "      <td>572e8003c246551400ce425f</td>\n",
              "      <td>what did great britain gain in the west indies...</td>\n",
              "      <td>many middle and small powers in europe, unlike...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>113</td>\n",
              "      <td>some individual caribbean islands in the west ...</td>\n",
              "      <td>15282</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66972</th>\n",
              "      <td>572e81f2cb0c0d14000f1206</td>\n",
              "      <td>what is the precedent for the \"second hundred ...</td>\n",
              "      <td>the war was successful for great britain, whic...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>446</td>\n",
              "      <td>reminiscent of the more famous and compact str...</td>\n",
              "      <td>15283</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67376</th>\n",
              "      <td>572e8578c246551400ce42bd</td>\n",
              "      <td>who would sicily and savoy normally align with?</td>\n",
              "      <td>realizing that war was imminent, prussia preem...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>434</td>\n",
              "      <td>sicily, and savoy, although sided with franco-...</td>\n",
              "      <td>15281</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69867</th>\n",
              "      <td>56e180f5e3433e1400422f96</td>\n",
              "      <td>what do the dialects of catalan feature?</td>\n",
              "      <td>catalan sociolinguistics studies the situation...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>56</td>\n",
              "      <td>uniformity</td>\n",
              "      <td>3471</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69923</th>\n",
              "      <td>56e17f5de3433e1400422f90</td>\n",
              "      <td>what outside affects does this study include?</td>\n",
              "      <td>in central catalan, unstressed vowels reduce t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>331</td>\n",
              "      <td>other languages in contact</td>\n",
              "      <td>3470</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ... end\n",
              "87     56de31984396321400ee2672  ...  -1\n",
              "3133   56e17f5de3433e1400422f8c  ...  -1\n",
              "3983   56e1b97fcd28a01900c67ad8  ...  -1\n",
              "6198   56e1b4decd28a01900c67a91  ...  -1\n",
              "6994   56e1b738cd28a01900c67aae  ...  -1\n",
              "...                         ...  ...  ..\n",
              "66889  572e8003c246551400ce425f  ...  -1\n",
              "66972  572e81f2cb0c0d14000f1206  ...  -1\n",
              "67376  572e8578c246551400ce42bd  ...  -1\n",
              "69867  56e180f5e3433e1400422f96  ...  -1\n",
              "69923  56e17f5de3433e1400422f90  ...  -1\n",
              "\n",
              "[69 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o7uz1Odj7fAS",
        "outputId": "48243f61-5d45-4899-b4f6-0c03e330492d"
      },
      "source": [
        "vl_df[vl_df['start'] == -1]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>56e18a90e3433e1400422fac</td>\n",
              "      <td>in what densely populated area is it spoken?</td>\n",
              "      <td>western catalan comprises the two dialects of ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>166</td>\n",
              "      <td>barcelona province</td>\n",
              "      <td>3474</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>56e1a3cbe3433e1400423066</td>\n",
              "      <td>where is iec's standard used?</td>\n",
              "      <td>standard catalan, virtually accepted by all sp...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>3</td>\n",
              "      <td>the balearic islands</td>\n",
              "      <td>3484</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3007</th>\n",
              "      <td>56e18710cd28a01900c679b9</td>\n",
              "      <td>what have a and e done in eastern dialects?</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>162</td>\n",
              "      <td>merged</td>\n",
              "      <td>3472</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4925</th>\n",
              "      <td>56e1b4decd28a01900c67a8e</td>\n",
              "      <td>where is the catalan speaking part of aragon?</td>\n",
              "      <td>in alghero, the iec has adapted its standard t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>114</td>\n",
              "      <td>la franja</td>\n",
              "      <td>3486</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5782</th>\n",
              "      <td>56e18bfbe3433e1400422fb5</td>\n",
              "      <td>how many stressed phonemes are there in catalan?</td>\n",
              "      <td>central catalan is considered the standard pro...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>69</td>\n",
              "      <td>seven</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5897</th>\n",
              "      <td>56e18710cd28a01900c679b7</td>\n",
              "      <td>what is the major difference between the two b...</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>118</td>\n",
              "      <td>treatment of unstressed a and e</td>\n",
              "      <td>3472</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5937</th>\n",
              "      <td>56e18bfbe3433e1400422fb4</td>\n",
              "      <td>what is the vowel system of catalan?</td>\n",
              "      <td>western catalan comprises the two dialects of ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>50</td>\n",
              "      <td>vulgar latin</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6561</th>\n",
              "      <td>56e1b264e3433e14004230a6</td>\n",
              "      <td>where has the iec adapted its standard to the ...</td>\n",
              "      <td>the most notable difference between both stand...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>3</td>\n",
              "      <td>alghero</td>\n",
              "      <td>3485</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7378</th>\n",
              "      <td>572e81f2cb0c0d14000f1207</td>\n",
              "      <td>what was a later conflict that some considered...</td>\n",
              "      <td>the war was successful for great britain, whic...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>246</td>\n",
              "      <td>to later conflicts like the napoleonic wars</td>\n",
              "      <td>15283</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11252</th>\n",
              "      <td>56e17b08cd28a01900c679af</td>\n",
              "      <td>where do you find dialectic vowel reductions?</td>\n",
              "      <td>catalan has inherited the typical vowel system...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>176</td>\n",
              "      <td>section pronunciation</td>\n",
              "      <td>3469</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11511</th>\n",
              "      <td>56de31f34396321400ee2680</td>\n",
              "      <td>does the ihdi measure the \"average\" or the \"po...</td>\n",
              "      <td>the 2013 human development report by the unite...</td>\n",
              "      <td>Human_Development_Index</td>\n",
              "      <td>72</td>\n",
              "      <td>the average level</td>\n",
              "      <td>2182</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12438</th>\n",
              "      <td>56e188e4cd28a01900c679c0</td>\n",
              "      <td>how many dialects are in the eastern group?</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>110</td>\n",
              "      <td>four</td>\n",
              "      <td>3473</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16218</th>\n",
              "      <td>56e180f5e3433e1400422f97</td>\n",
              "      <td>in comparison to what are the dialects uniform?</td>\n",
              "      <td>catalan sociolinguistics studies the situation...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>96</td>\n",
              "      <td>other romance languages</td>\n",
              "      <td>3471</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16474</th>\n",
              "      <td>56e1b738cd28a01900c67aaf</td>\n",
              "      <td>what forms are mutually intelligible?</td>\n",
              "      <td>in 2011, the aragonese government passed a dec...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>190</td>\n",
              "      <td>catalan and valencian</td>\n",
              "      <td>3487</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17282</th>\n",
              "      <td>56e18bfbe3433e1400422fb6</td>\n",
              "      <td>where is this system common?</td>\n",
              "      <td>central catalan is considered the standard pro...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>131</td>\n",
              "      <td>western romance</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ... end\n",
              "171    56e18a90e3433e1400422fac  ...  -1\n",
              "1536   56e1a3cbe3433e1400423066  ...  -1\n",
              "3007   56e18710cd28a01900c679b9  ...  -1\n",
              "4925   56e1b4decd28a01900c67a8e  ...  -1\n",
              "5782   56e18bfbe3433e1400422fb5  ...  -1\n",
              "5897   56e18710cd28a01900c679b7  ...  -1\n",
              "5937   56e18bfbe3433e1400422fb4  ...  -1\n",
              "6561   56e1b264e3433e14004230a6  ...  -1\n",
              "7378   572e81f2cb0c0d14000f1207  ...  -1\n",
              "11252  56e17b08cd28a01900c679af  ...  -1\n",
              "11511  56de31f34396321400ee2680  ...  -1\n",
              "12438  56e188e4cd28a01900c679c0  ...  -1\n",
              "16218  56e180f5e3433e1400422f97  ...  -1\n",
              "16474  56e1b738cd28a01900c67aaf  ...  -1\n",
              "17282  56e18bfbe3433e1400422fb6  ...  -1\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ3CXWdL8CNk"
      },
      "source": [
        "# we get rid of samples where the answer doesn't match the context\r\n",
        "tr_df = tr_df[tr_df['start'] != -1]\r\n",
        "vl_df = vl_df[vl_df['start'] != -1]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_KJeyPxVZG6"
      },
      "source": [
        "tr_df = tokenize(tr_df, tokenizer, char_tokenizer)\r\n",
        "vl_df = tokenize(vl_df, tokenizer, char_tokenizer)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "VJd7p05zjg0e",
        "outputId": "516ab8d3-19b8-48f0-f89f-a7e67adc2f8d"
      },
      "source": [
        "tr_df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>tokenized_question</th>\n",
              "      <th>tokenized_context</th>\n",
              "      <th>char_tokenized_question</th>\n",
              "      <th>char_tokenized_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572667e6708984140094c4f9</td>\n",
              "      <td>what team had dallas green managed in 1980?</td>\n",
              "      <td>after over a dozen more subpar seasons, in 198...</td>\n",
              "      <td>Chicago_Cubs</td>\n",
              "      <td>154</td>\n",
              "      <td>phillies</td>\n",
              "      <td>8880</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>[11, 309, 49, 11808, 646, 2132, 6, 2627, 9]</td>\n",
              "      <td>[61, 83, 10, 6737, 62, 70020, 1740, 3, 6, 3372...</td>\n",
              "      <td>[[20, 11, 5, 4], [4, 3, 5, 16], [11, 5, 13], [...</td>\n",
              "      <td>[[5, 17, 4, 3, 10], [8, 24, 3, 10], [5], [13, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56dec2483277331400b4d712</td>\n",
              "      <td>which candidate withdrew from the presidential...</td>\n",
              "      <td>schwarzenegger's endorsement in the republican...</td>\n",
              "      <td>Arnold_Schwarzenegger</td>\n",
              "      <td>156</td>\n",
              "      <td>rudy giuliani</td>\n",
              "      <td>2311</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>[27, 2789, 4161, 23, 2, 1534, 698, 6, 417, 4, ...</td>\n",
              "      <td>[1084, 19, 9106, 6, 2, 1467, 477, 4, 2, 420, 1...</td>\n",
              "      <td>[[20, 11, 6, 14, 11], [14, 5, 7, 13, 6, 13, 5,...</td>\n",
              "      <td>[[9, 14, 11, 20, 5, 10, 39, 3, 7, 3, 19, 19, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5726e5995951b619008f81bb</td>\n",
              "      <td>captive animals can distinguish co-inhabitats ...</td>\n",
              "      <td>it has been observed that well-fed predator an...</td>\n",
              "      <td>Predation</td>\n",
              "      <td>224</td>\n",
              "      <td>wild ones outside the area</td>\n",
              "      <td>9822</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "      <td>[11888, 727, 65, 3733, 419169, 23, 11, 48, 136...</td>\n",
              "      <td>[30, 40, 59, 2316, 20, 63225, 4421, 727, 6, 10...</td>\n",
              "      <td>[[14, 5, 18, 4, 6, 24, 3], [5, 7, 6, 16, 5, 12...</td>\n",
              "      <td>[[6, 4], [11, 5, 9], [22, 3, 3, 7], [8, 22, 9,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5726486f708984140094c157</td>\n",
              "      <td>the results of which battle allowed the britis...</td>\n",
              "      <td>after returning from egypt, napoleon engineere...</td>\n",
              "      <td>Napoleon</td>\n",
              "      <td>919</td>\n",
              "      <td>the battle of trafalgar</td>\n",
              "      <td>8418</td>\n",
              "      <td>158</td>\n",
              "      <td>162</td>\n",
              "      <td>[2, 1324, 4, 27, 326, 495, 2, 132, 8, 6280, 15...</td>\n",
              "      <td>[61, 3986, 23, 598, 3, 545, 9789, 10, 2313, 6,...</td>\n",
              "      <td>[[4, 11, 3], [10, 3, 9, 15, 12, 4, 9], [8, 17]...</td>\n",
              "      <td>[[5, 17, 4, 3, 10], [10, 3, 4, 15, 10, 7, 6, 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5730299db2c2fd14005689a7</td>\n",
              "      <td>how was vesey executed in 1822?</td>\n",
              "      <td>by 1820, charleston's population had grown to ...</td>\n",
              "      <td>Charleston,_South_Carolina</td>\n",
              "      <td>382</td>\n",
              "      <td>hanged</td>\n",
              "      <td>15719</td>\n",
              "      <td>74</td>\n",
              "      <td>75</td>\n",
              "      <td>[44, 13, 25121, 2181, 6, 10202, 9]</td>\n",
              "      <td>[18, 9015, 3, 1909, 19, 104, 49, 2555, 8, 2106...</td>\n",
              "      <td>[[11, 8, 20], [20, 5, 9], [24, 3, 9, 3, 21], [...</td>\n",
              "      <td>[[22, 21], [28, 40, 31, 29], [23], [14, 11, 5,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ...                             char_tokenized_context\n",
              "0  572667e6708984140094c4f9  ...  [[5, 17, 4, 3, 10], [8, 24, 3, 10], [5], [13, ...\n",
              "1  56dec2483277331400b4d712  ...  [[9, 14, 11, 20, 5, 10, 39, 3, 7, 3, 19, 19, 3...\n",
              "2  5726e5995951b619008f81bb  ...  [[6, 4], [11, 5, 9], [22, 3, 3, 7], [8, 22, 9,...\n",
              "3  5726486f708984140094c157  ...  [[5, 17, 4, 3, 10], [10, 3, 4, 15, 10, 7, 6, 7...\n",
              "4  5730299db2c2fd14005689a7  ...  [[22, 21], [28, 40, 31, 29], [23], [14, 11, 5,...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kw5Pk4c6I3S",
        "outputId": "b3efb93e-785e-487b-ce2f-33db48e7523f"
      },
      "source": [
        "print(tr_df['tokenized_question'].str.len().describe())\r\n",
        "vl_df['tokenized_question'].str.len().describe()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    70010.000000\n",
            "mean        11.275532\n",
            "std          3.715821\n",
            "min          1.000000\n",
            "25%          9.000000\n",
            "50%         11.000000\n",
            "75%         13.000000\n",
            "max         60.000000\n",
            "Name: tokenized_question, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    17505.000000\n",
              "mean        11.335504\n",
              "std          3.754207\n",
              "min          1.000000\n",
              "25%          9.000000\n",
              "50%         11.000000\n",
              "75%         13.000000\n",
              "max         38.000000\n",
              "Name: tokenized_question, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk5TG_Yy9crW",
        "outputId": "062a9fc8-e9af-4e19-e241-0f21c9f181f6"
      },
      "source": [
        "print(tr_df['tokenized_question'].str.len().quantile(0.99))\r\n",
        "vl_df['tokenized_question'].str.len().quantile(0.99)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsKYKsgR6-UK",
        "outputId": "248f5379-8456-444b-a7d2-481f56acac6a"
      },
      "source": [
        "print(tr_df['tokenized_context'].str.len().describe())\r\n",
        "vl_df['tokenized_context'].str.len().describe()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    70010.000000\n",
            "mean       137.824439\n",
            "std         56.941382\n",
            "min         22.000000\n",
            "25%        102.000000\n",
            "50%        127.000000\n",
            "75%        164.000000\n",
            "max        766.000000\n",
            "Name: tokenized_context, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    17505.000000\n",
              "mean       137.211083\n",
              "std         55.912622\n",
              "min         22.000000\n",
              "25%        102.000000\n",
              "50%        126.000000\n",
              "75%        163.000000\n",
              "max        766.000000\n",
              "Name: tokenized_context, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyp5MUtj9woq",
        "outputId": "dd9f4e38-3d26-40d6-8e53-0310220bfa76"
      },
      "source": [
        "print(tr_df['tokenized_context'].str.len().quantile(0.99))\r\n",
        "vl_df['tokenized_context'].str.len().quantile(0.99)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "324.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE3J6xJZ7Sqe"
      },
      "source": [
        "def len_words(dataset):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  return the word's length\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  count_q = []\r\n",
        "  count_c = []\r\n",
        "\r\n",
        "  for idx, row in dataset.iterrows():\r\n",
        "    for w in row['char_tokenized_question']:\r\n",
        "      l = len(w)\r\n",
        "      count_q.append(l)\r\n",
        "      \r\n",
        "    for w in row['char_tokenized_context']:\r\n",
        "      m = len(w)\r\n",
        "      count_c.append(m)\r\n",
        "  \r\n",
        "  return pd.Series(count_q), pd.Series(count_c)\r\n",
        "\r\n",
        "t_q,t_c = len_words(tr_df)\r\n",
        "v_q,v_c = len_words(vl_df)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8R_-bUv9HGQ",
        "outputId": "310fdddc-fdd5-4f9f-a6ee-0b3731bc6e25"
      },
      "source": [
        "print(t_q.describe())\r\n",
        "t_c.describe()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    789400.000000\n",
            "mean          4.447926\n",
            "std           2.677579\n",
            "min           1.000000\n",
            "25%           2.000000\n",
            "50%           4.000000\n",
            "75%           6.000000\n",
            "max          30.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    9.649089e+06\n",
              "mean     4.626070e+00\n",
              "std      2.969605e+00\n",
              "min      1.000000e+00\n",
              "25%      2.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      7.000000e+00\n",
              "max      3.700000e+01\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R64fJS7DxkuN",
        "outputId": "7db31830-92d4-48e1-85bc-266a308e2722"
      },
      "source": [
        "print(v_q.describe())\r\n",
        "v_c.describe()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    198428.000000\n",
            "mean          4.453232\n",
            "std           2.686696\n",
            "min           1.000000\n",
            "25%           2.000000\n",
            "50%           4.000000\n",
            "75%           6.000000\n",
            "max          24.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.401880e+06\n",
              "mean     4.629710e+00\n",
              "std      2.972670e+00\n",
              "min      1.000000e+00\n",
              "25%      2.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      7.000000e+00\n",
              "max      3.700000e+01\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wxf3tS7xylx",
        "outputId": "b15ede09-988e-4a1f-f147-38d5b0fba764"
      },
      "source": [
        "print(t_q.quantile(0.99))\r\n",
        "t_c.quantile(0.99)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6F-O0qjx4Gu",
        "outputId": "62147276-9042-49c9-b89a-b7de8d661148"
      },
      "source": [
        "print(v_q.quantile(0.99))\r\n",
        "v_c.quantile(0.99)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC1K9nYs9ht2"
      },
      "source": [
        "There are obviously some outliers. We are compeled to get rid of some samples because of memory issues.\r\n",
        "\r\n",
        "We will get rid of contexts that have more than 400 words and questions that have more than 25 words.\r\n",
        "\r\n",
        "We will set the length of a word to 15 characters\r\n",
        "\r\n",
        "**EDIT :** These numbers are huge but we won't get out of memory errors if we build a sequence generator. If you don't want to use the sequence generator, you should reduce these numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WiAI_oA_3lY"
      },
      "source": [
        "QUESTION_MAXLEN = 25\r\n",
        "CONTEXT_MAXLEN = 400\r\n",
        "WORD_MAXLEN = 15\r\n",
        "BATCH_SIZE = 10"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZMoWqTL2Wz",
        "outputId": "1cb1d6d6-49a3-4e21-9ea3-12f4a2d6dfde"
      },
      "source": [
        "tr_df.shape, vl_df.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70010, 13), (17505, 13))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibILzhoh-Mf8"
      },
      "source": [
        "tr_df = tr_df[(tr_df['tokenized_question'].str.len() <= QUESTION_MAXLEN) & (tr_df['tokenized_context'].str.len() <= CONTEXT_MAXLEN) & (tr_df['start'] <= CONTEXT_MAXLEN) & (tr_df['end'] <= CONTEXT_MAXLEN) ].reset_index(drop = True)\r\n",
        "vl_df = vl_df[(vl_df['tokenized_question'].str.len() <= QUESTION_MAXLEN) & (vl_df['tokenized_context'].str.len() <= CONTEXT_MAXLEN) & (vl_df['start'] <= CONTEXT_MAXLEN) & (vl_df['end'] <= CONTEXT_MAXLEN) ].reset_index(drop = True)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQTuvAo7oGcA",
        "outputId": "6e9afdde-013f-45d7-eb25-71c76f7ba0c1"
      },
      "source": [
        "tr_df.shape[0], vl_df.shape[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69606, 17413)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93mWQxFLG3z9",
        "outputId": "86fc2128-63ae-4b2c-8344-d2254339c866"
      },
      "source": [
        " print(f' we get rid of : {SAMPLES - (tr_df.shape[0] + vl_df.shape[0])} samples')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " we get rid of : 580 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lFv9wpDfDOj",
        "outputId": "84b36b8b-17ab-4997-ba04-20d5f5e6c08d"
      },
      "source": [
        "# save datasets in json format\r\n",
        "path_to_train_set = os.path.join(os.getcwd(), 'BERT_train_set.json')\r\n",
        "df_to_json(tr_df, path_to_train_set)\r\n",
        "\r\n",
        "path_to_valid_set = os.path.join(os.getcwd(), 'BERT_valid_set.json')\r\n",
        "df_to_json(vl_df, path_to_valid_set)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset saved in /content/BERT_train_set.json\n",
            "dataset saved in /content/BERT_valid_set.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owvocjs5JCPa"
      },
      "source": [
        "# we save both tokenizers\r\n",
        "tokenizers_folder = os.getcwd()\r\n",
        "if not os.path.exists(tokenizers_folder):\r\n",
        "  os.makedirs(tokenizers_folder)\r\n",
        "\r\n",
        "path_word_tokenizer = os.path.join(tokenizers_folder, 'word_tokenizer.pkl')\r\n",
        "with open(path_word_tokenizer, 'wb') as handle:\r\n",
        "    pickle.dump(tokenizer, handle, protocol = pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "path_char_tokenizer = os.path.join(tokenizers_folder, 'char_tokenizer.pkl')\r\n",
        "with open(path_char_tokenizer, 'wb') as handle:\r\n",
        "    pickle.dump(char_tokenizer, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX5aJeXaqnZh"
      },
      "source": [
        "We create the iterator. The iterator allows us to work with much bigger data, because it is loaded into memory only when we need them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMEr6c_hiv6Q"
      },
      "source": [
        "# utils/datasets/dataset.py\r\n",
        "class SQUAD_dataset(tf.keras.utils.Sequence):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  utility class to create a working dataset that\r\n",
        "  can be given to a neural network\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  def __init__(self, data, question_maxlen, context_maxlen, word_maxlen, batch_size):\r\n",
        "    self.QUESTION_MAXLEN = question_maxlen\r\n",
        "    self.CONTEXT_MAXLEN = context_maxlen\r\n",
        "    self.WORD_MAXLEN = word_maxlen\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.__get_batches(data)\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.batches)\r\n",
        "\r\n",
        "  def __get_batches(self, data):\r\n",
        "    batches = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\r\n",
        "    self.batches = batches\r\n",
        "\r\n",
        "  def __repr__(self):\r\n",
        "    template = '''SQUAD_dataset : questions : ({0}, {1}), contexts : ({0}, {2}), char_questions : ({0}, {1}, {3}), char_contexts : ({0}, {2}, {3}), index : ({0}, 1)'''.format(self.batch_size, self.QUESTION_MAXLEN, self.CONTEXT_MAXLEN, self.WORD_MAXLEN)\r\n",
        "    return template\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def from_file(cls, path):\r\n",
        "    path = os.path.join(os.getcwd(), path)\r\n",
        "    with open(path, 'rb') as handle:\r\n",
        "      dataset = pickle.load(handle)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "  def to_pickle(self, path):\r\n",
        "    path = os.path.join(os.getcwd(), path)\r\n",
        "    folder = os.path.dirname(path)\r\n",
        "\r\n",
        "    if not os.path.exists(folder):\r\n",
        "      os.makedirs(folder)\r\n",
        "\r\n",
        "    with open(path, 'wb') as handle:\r\n",
        "      pickle.dump(self, handle, protocol = pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "  def __getitem__(self, idx):\r\n",
        "    batch = self.batches[idx].reset_index(drop = True)\r\n",
        "\r\n",
        "    index = np.asarray(batch['index'])\r\n",
        "\r\n",
        "    # questions and contexts words padding\r\n",
        "    q_w = tf.keras.preprocessing.sequence.pad_sequences(batch['tokenized_question'], padding = 'post', maxlen = self.QUESTION_MAXLEN)\r\n",
        "    c_w = tf.keras.preprocessing.sequence.pad_sequences(batch['tokenized_context'], padding = 'post', maxlen = self.CONTEXT_MAXLEN)\r\n",
        "\r\n",
        "    # question_char padding\r\n",
        "    q_c = np.zeros((q_w.shape[0], self.QUESTION_MAXLEN, self.WORD_MAXLEN), dtype = np.int32)\r\n",
        "\r\n",
        "    for i, value in batch['char_tokenized_question'].iteritems():\r\n",
        "      v = tf.keras.preprocessing.sequence.pad_sequences(value, padding = 'post', maxlen = self.WORD_MAXLEN, truncating = 'post')\r\n",
        "      to_add = self.QUESTION_MAXLEN - v.shape[0]\r\n",
        "      add = np.zeros((to_add, self.WORD_MAXLEN))\r\n",
        "      arr = np.vstack([v,add])\r\n",
        "      q_c[i] = arr\r\n",
        "\r\n",
        "    # context_chr padding\r\n",
        "    c_c = np.zeros((q_w.shape[0], self.CONTEXT_MAXLEN, self.WORD_MAXLEN), dtype = np.int32)\r\n",
        "\r\n",
        "    for i, value in batch['char_tokenized_context'].iteritems():\r\n",
        "      v = tf.keras.preprocessing.sequence.pad_sequences(value, padding = 'post', maxlen = self.WORD_MAXLEN, truncating = 'post')\r\n",
        "      to_add = self.CONTEXT_MAXLEN - v.shape[0]\r\n",
        "      add = np.zeros((to_add, self.WORD_MAXLEN))\r\n",
        "      arr = np.vstack([v,add])\r\n",
        "      c_c[i] = arr\r\n",
        "\r\n",
        "    # one hot encode start and end\r\n",
        "    y_start = tf.keras.utils.to_categorical(batch['start'].values, self.CONTEXT_MAXLEN)\r\n",
        "    y_end = tf.keras.utils.to_categorical(batch['end'].values, self.CONTEXT_MAXLEN)\r\n",
        "\r\n",
        "    # (inputs), (outputs), (index)\r\n",
        "    return (q_w, c_w, q_c, c_c), (y_start, y_end), (index,)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTS5gSunCRa"
      },
      "source": [
        "tr_data = SQUAD_dataset(tr_df, batch_size = BATCH_SIZE, question_maxlen = QUESTION_MAXLEN, context_maxlen = CONTEXT_MAXLEN, word_maxlen = WORD_MAXLEN)\r\n",
        "vl_data = SQUAD_dataset(vl_df, batch_size = BATCH_SIZE, question_maxlen = QUESTION_MAXLEN, context_maxlen = CONTEXT_MAXLEN, word_maxlen = WORD_MAXLEN)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VciOKiQtyAx",
        "outputId": "4cad88f2-37ce-4f95-bc98-ab021e197912"
      },
      "source": [
        "# number of batches\r\n",
        "print(len(tr_data))\r\n",
        "len(vl_data)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1742"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GtQIVC9zZ5g",
        "outputId": "85439dac-9e9a-441b-9bfa-37b5df72d17e"
      },
      "source": [
        "tr_data"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SQUAD_dataset : questions : (10, 25), contexts : (10, 400), char_questions : (10, 25, 15), char_contexts : (10, 400, 15), index : (10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbiAh9h1-Fg"
      },
      "source": [
        "tr_data.to_pickle('train_dataset.pkl')\r\n",
        "vl_data.to_pickle('valid_dataset.pkl')"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}