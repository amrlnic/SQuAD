{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55828WPMjIbR"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEbFUGQyh6ch"
      },
      "source": [
        "%%capture\r\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5heFvOoGiP8h"
      },
      "source": [
        "import os, re, json, requests, io, string\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tokenizers import BertWordPieceTokenizer\r\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "\r\n",
        "MAX_LEN = 384\r\n",
        "random.seed(42)\r\n",
        "configuration = BertConfig()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifdy9499Jl-v",
        "outputId": "d2751b83-121a-4f29-f6f6-07e49559c7b1"
      },
      "source": [
        "# Load the Drive helper and mount -> we could use this to save the weights of the models\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns95EZ9jjXL_"
      },
      "source": [
        "# Set up tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO1kSoCVjg2X"
      },
      "source": [
        "# Save the slow pretrained tokenizer\r\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "save_path = \"bert_base_uncased/\"\r\n",
        "if not os.path.exists(save_path):\r\n",
        "    os.makedirs(save_path)\r\n",
        "slow_tokenizer.save_pretrained(save_path)\r\n",
        "\r\n",
        "# Load the fast tokenizer from saved file\r\n",
        "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFJwoUhjlZR"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0jaIxPTLmxH",
        "outputId": "69e85d47-74aa-4d8f-f529-1d3e079bb460"
      },
      "source": [
        "\r\n",
        "url = \"https://raw.githubusercontent.com/amrlnic/SQuAD/main/data/training_set.json\" # Make sure the url is the raw version of the file on GitHub\r\n",
        "download = requests.get(url).content\r\n",
        "data = json.loads(download)\r\n",
        "\r\n",
        "def load_dataset(file, record_path = ['data', 'paragraphs', 'qas', 'answers'], verbose = True):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the SQUAD dataset into a dataframe\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"Reading the json file\")\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"[INFO] processing...\")\r\n",
        "\r\n",
        "  # parsing different level's in the json file\r\n",
        "  js = pd.json_normalize(file , record_path )\r\n",
        "  m = pd.json_normalize(file, record_path[:-1] )\r\n",
        "  r = pd.json_normalize(file, record_path[:-2])\r\n",
        "  t = pd.json_normalize(file, record_path[0])\r\n",
        "\r\n",
        "  title = pd.json_normalize(file['data'], record_path = ['paragraphs'], meta = 'title')\r\n",
        "\r\n",
        "  #combining it into single dataframe\r\n",
        "  idx = np.repeat(r['context'].values, r.qas.str.len())\r\n",
        "  ndx  = np.repeat(m['id'].values, m['answers'].str.len())\r\n",
        "  m['context'] = idx\r\n",
        "  m['title'] = np.repeat(title['title'].values, r.qas.str.len())\r\n",
        "  js['q_idx'] = ndx\r\n",
        "  main = pd.concat([ m[['id','question','context', 'title']].set_index('id'), js.set_index('q_idx')], 1, sort = False).reset_index()\r\n",
        "  main['c_id'] = main['context'].factorize()[0]\r\n",
        "  if verbose:\r\n",
        "      print(f\"[INFO] there are {main.shape[0]} questions with single answer\")\r\n",
        "      print(f\"[INFO] there are {main.groupby('c_id').sum().shape[0]} different contexts\")\r\n",
        "      print(f\"[INFO] there are {len(t)} unrelated subjects\")\r\n",
        "      print(\"[INFO] Done\")\r\n",
        "  return main\r\n",
        "\r\n",
        "squad_dataset = load_dataset(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the json file\n",
            "[INFO] processing...\n",
            "[INFO] there are 87599 questions with single answer\n",
            "[INFO] there are 18891 different contexts\n",
            "[INFO] there are 442 unrelated subjects\n",
            "[INFO] Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "lzHPUWA45dzO",
        "outputId": "aca16f64-e80a-4776-e17a-c2a862bc864a"
      },
      "source": [
        "squad_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>188</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ... c_id\n",
              "0  5733be284776f41900661182  ...    0\n",
              "1  5733be284776f4190066117f  ...    0\n",
              "2  5733be284776f41900661180  ...    0\n",
              "3  5733be284776f41900661181  ...    0\n",
              "4  5733be284776f4190066117e  ...    0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akd8JN0Z7Isv"
      },
      "source": [
        "# Pre - processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCWKKV2RAhML"
      },
      "source": [
        "SAMPLES = squad_dataset.shape[0]\r\n",
        "\r\n",
        "def preprocess_sentence(text):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  lowercase and strip the given text\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  text = text.lower()\r\n",
        "  text = text.strip()\r\n",
        "  return text\r\n",
        "\r\n",
        "def clean_dataset(dataset):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  preprocess the dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  _dataset = dataset.copy()\r\n",
        "\r\n",
        "  cleaned_questions = _dataset['question'].apply(preprocess_sentence)\r\n",
        "  cleaned_texts = _dataset['text'].apply(preprocess_sentence)\r\n",
        "\r\n",
        "  # we process only different contexts and then we duplicate them\r\n",
        "  unique_context = pd.Series(_dataset['context'].unique())\r\n",
        "  count_c = _dataset.groupby('c_id').count()['text']\r\n",
        "  cleaned_contexts = unique_context.apply(preprocess_sentence)\r\n",
        "\r\n",
        "  _dataset['question'] = cleaned_questions\r\n",
        "  _dataset['text'] = cleaned_texts\r\n",
        "  _dataset['context'] = pd.Series(np.repeat(cleaned_contexts, count_c).tolist())\r\n",
        "\r\n",
        "  return _dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSVZ45xxqqqz"
      },
      "source": [
        "squad_dataset = clean_dataset(squad_dataset)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgvUMpP7RjKl"
      },
      "source": [
        "# Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7q_hIu8RUDI"
      },
      "source": [
        "def split(dataset, train_size = 0.8):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  split the dataset in two part: the training and the validation\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # find unique titles\r\n",
        "  titles = squad_dataset['title']\r\n",
        "  unique_titles = titles.unique()\r\n",
        "\r\n",
        "\r\n",
        "  n_titles = len(unique_titles)\r\n",
        "  titles_seq = list(range(n_titles))\r\n",
        "\r\n",
        "  train_len = int(n_titles*train_size)\r\n",
        "\r\n",
        "  # sample train indexes\r\n",
        "  train_ind = random.sample(titles_seq, train_len)\r\n",
        "  test_ind = list(set(titles_seq) - set(train_ind))\r\n",
        "\r\n",
        "  train_titles = unique_titles[train_ind]\r\n",
        "  test_titles = unique_titles[test_ind]\r\n",
        "\r\n",
        "  squad_columns = list(squad_dataset.columns)\r\n",
        "\r\n",
        "  # initialize empty train and test df\r\n",
        "  train_data = pd.DataFrame(columns = squad_columns)\r\n",
        "  test_data = pd.DataFrame(columns = squad_columns)\r\n",
        "\r\n",
        "  for train_title in train_titles:\r\n",
        "\r\n",
        "    train_section = squad_dataset[squad_dataset['title'] == train_title]\r\n",
        "    train_data = train_data.append(train_section)\r\n",
        "\r\n",
        "  for test_title in test_titles:\r\n",
        "\r\n",
        "    test_section = squad_dataset[squad_dataset['title'] == test_title]\r\n",
        "    test_data = test_data.append(test_section)\r\n",
        "\r\n",
        "\r\n",
        "  return train_data, test_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmlwoWxZRdt6",
        "outputId": "58a44f68-0f07-4bcd-a871-fefbfb3d2abe"
      },
      "source": [
        "tr_df, vl_df = split(squad_dataset)\r\n",
        "tr_df.shape[0],vl_df.shape[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69129, 18470)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8kC65SqDvTZ"
      },
      "source": [
        "# Filter rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq8B58osDLvX"
      },
      "source": [
        "def skip(row):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  Create the input sequences and find the rows that we have to skip\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  answer = row['text']\r\n",
        "  context = row['context']\r\n",
        "  start_char_idx = row['answer_start']\r\n",
        "  question = row['question']\r\n",
        "\r\n",
        "  # initialize skip column\r\n",
        "  row['skip'] = False\r\n",
        "\r\n",
        "\r\n",
        "  # Find end character index of answer in context\r\n",
        "  end_char_idx = start_char_idx + len(answer)\r\n",
        "  if end_char_idx >= len(context):\r\n",
        "    row['skip'] = True\r\n",
        "    return row\r\n",
        "\r\n",
        "  # Mark the character indexes in context that are in answer\r\n",
        "  is_char_in_ans = [0] * len(context)\r\n",
        "  for idx in range(start_char_idx, end_char_idx):\r\n",
        "    is_char_in_ans[idx] = 1\r\n",
        "\r\n",
        "  # Tokenize context\r\n",
        "  tokenized_context = tokenizer.encode(context)\r\n",
        "  row['tokenized context'] = tokenized_context\r\n",
        "\r\n",
        "  # Find tokens that were created from answer characters\r\n",
        "  ans_token_idx = []\r\n",
        "  for idx, (start, end) in enumerate(tokenized_context.offsets):\r\n",
        "    if sum(is_char_in_ans[start:end]) > 0:\r\n",
        "      ans_token_idx.append(idx)\r\n",
        "\r\n",
        "  if len(ans_token_idx) == 0:\r\n",
        "    row['skip'] = True\r\n",
        "    return row\r\n",
        "\r\n",
        "  # Find start and end token index for tokens from answer\r\n",
        "  start_token_idx = ans_token_idx[0]\r\n",
        "  end_token_idx = ans_token_idx[-1]\r\n",
        "\r\n",
        "  row['start token idx'] = start_token_idx\r\n",
        "  row['end token idx'] = end_token_idx\r\n",
        "\r\n",
        "  # Tokenize question\r\n",
        "  tokenized_question = tokenizer.encode(question)\r\n",
        "  row['tokenized question'] = tokenized_question\r\n",
        "\r\n",
        "  # Inputs of the model: here are used to determine whether to skip the row or not\r\n",
        "  input_ids = tokenized_context.ids + tokenized_question.ids[1:]\r\n",
        "  token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\r\n",
        "            tokenized_question.ids[1:]\r\n",
        "        )\r\n",
        "  attention_mask = [1] * len(input_ids)\r\n",
        "\r\n",
        "  padding_length = MAX_LEN - len(input_ids)\r\n",
        "\r\n",
        "  if padding_length > 0:  # pad\r\n",
        "    input_ids = input_ids + ([0] * padding_length)\r\n",
        "    attention_mask = attention_mask + ([0] * padding_length)\r\n",
        "    token_type_ids = token_type_ids + ([0] * padding_length)\r\n",
        "  elif padding_length < 0:\r\n",
        "    row['skip'] = True\r\n",
        "  \r\n",
        "  row['input ids'] = np.array(input_ids)\r\n",
        "  row['token type ids'] = np.array(token_type_ids)\r\n",
        "  row['attention mask'] = np.array(attention_mask)\r\n",
        "\r\n",
        "  return row\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eTsENy6jU-t",
        "outputId": "f0e4879d-1cab-4e4c-c740-58fe91e557c8"
      },
      "source": [
        "# takes a while\r\n",
        "tr_df = tr_df.apply(skip, axis = 1)\r\n",
        "vl_df = vl_df.apply(skip, axis = 1)\r\n",
        "\r\n",
        "len(tr_df[tr_df['skip']]), len(vl_df[vl_df['skip']])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1031, 421)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ3CXWdL8CNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d0169f-6fa2-4c06-a947-da0a63397199"
      },
      "source": [
        "# we get rid of samples where the answer doesn't match the context\r\n",
        "\r\n",
        "tr_df = tr_df[tr_df['skip'] == False]\r\n",
        "vl_df = vl_df[vl_df['skip'] == False]\r\n",
        "\r\n",
        "len(tr_df), len(vl_df)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68098, 18049)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVWNLTKlN2xq"
      },
      "source": [
        "# Save datasets as json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axtiEuSsN1Cn"
      },
      "source": [
        "def df_to_json(df, path):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the given dataframe into the SQUAD json format\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  data = []\r\n",
        "\r\n",
        "  for title, articles in df.groupby('title'):\r\n",
        "    chapter = {'title': title}\r\n",
        "    paragraphs = []\r\n",
        "    for context, contents in articles.groupby('context'):\r\n",
        "      paragraph = {'context': context}\r\n",
        "      qas = []\r\n",
        "      for i, content in contents.iterrows():\r\n",
        "        qa = {'answers': [{'answer_start': content['answer_start'], 'text': content['text']}], 'question': content['question'], 'id': content['index']}\r\n",
        "        qas.append(qa)\r\n",
        "      paragraph.update({'qas': qas})\r\n",
        "      paragraphs.append(paragraph)\r\n",
        "    chapter.update({'paragraphs': paragraphs})\r\n",
        "    data.append(chapter)\r\n",
        "  raw_data = {'data': data}\r\n",
        "\r\n",
        "  with open(path, 'w') as handle:\r\n",
        "    json.dump(raw_data, handle)\r\n",
        "\r\n",
        "  print(f'dataset saved in {path}')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lFv9wpDfDOj",
        "outputId": "0ca316f5-a294-463c-e295-a2d206a2abd0"
      },
      "source": [
        "# save datasets in json format\r\n",
        "path_to_train_set = os.path.join(os.getcwd(), 'BERT_train_set.json')\r\n",
        "df_to_json(tr_df, path_to_train_set)\r\n",
        "\r\n",
        "path_to_valid_set = os.path.join(os.getcwd(), 'BERT_valid_set.json')\r\n",
        "df_to_json(vl_df, path_to_valid_set)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset saved in /content/BERT_train_set.json\n",
            "dataset saved in /content/BERT_valid_set.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHS6UOM707bE"
      },
      "source": [
        "# Define input and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uI8ILDqkbaN"
      },
      "source": [
        "train_path = \"/content/gdrive/My Drive/Colab Notebooks/SQUAD_project/train_df\"\r\n",
        "val_path = \"/content/gdrive/My Drive/Colab Notebooks/SQUAD_project/val_df\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rLUe9YJ4dN"
      },
      "source": [
        "# Save dataframes on drive \r\n",
        "\r\n",
        "pickle.dump( tr_df, open(train_path, \"wb\" ) )\r\n",
        "pickle.dump( vl_df, open(val_path, \"wb\" ) )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkm4rVAHKiUm"
      },
      "source": [
        "# Load dataframes\r\n",
        "\r\n",
        "tr_df = pickle.load( open(train_path, \"rb\" ) )  \r\n",
        "vl_df = pickle.load( open(val_path, \"rb\" ) )  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGCwc1sb_fZL"
      },
      "source": [
        "def create_inputs_targets(squad_examples):\r\n",
        "\r\n",
        "  '''\r\n",
        "  Function to create inputs for the model\r\n",
        "\r\n",
        "  squad_examples (df)\r\n",
        "  '''\r\n",
        "\r\n",
        "  dataset_dict = {\r\n",
        "      \"input ids\": [],\r\n",
        "      \"token type ids\": [],\r\n",
        "      \"attention mask\": [],\r\n",
        "      \"start token idx\": [],\r\n",
        "      \"end token idx\": [],\r\n",
        "  }\r\n",
        "\r\n",
        "  n_items = len(squad_examples)\r\n",
        "  for i in range(n_items):\r\n",
        "    item = squad_examples.iloc[i]\r\n",
        "\r\n",
        "    for key in dataset_dict:\r\n",
        "      dataset_dict[key].append(getattr(item, key))\r\n",
        "\r\n",
        "  for key in dataset_dict:\r\n",
        "    dataset_dict[key] = np.array(dataset_dict[key])\r\n",
        "\r\n",
        "  x = [\r\n",
        "       dataset_dict[\"input ids\"],\r\n",
        "       dataset_dict[\"token type ids\"],\r\n",
        "       dataset_dict[\"attention mask\"],\r\n",
        "      ]\r\n",
        "  y = [dataset_dict[\"start token idx\"], dataset_dict[\"end token idx\"]]\r\n",
        "  return x, y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm2SvlR2Cegy"
      },
      "source": [
        "x_train, y_train = create_inputs_targets(tr_df)\r\n",
        "x_eval, y_eval = create_inputs_targets(vl_df)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-8L86bUpuRD"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH6_m_uD3D0m"
      },
      "source": [
        "def create_model(enc_dec = True, enc_dim = 128, dec_dim = 64, \r\n",
        "                 rec_mod = 'biLSTM', bert_ft = True, \r\n",
        "                 dropout = False, drop_prob = 0.5):\r\n",
        "\r\n",
        "    \"\"\" \r\n",
        "    Returns a keras model for predicting the start and the end of the answer\r\n",
        "\r\n",
        "    enc_dec (boolean): whether to use the encoder decoder model or not. If False, the base model will be used\r\n",
        "    enc_dim (int): encoding dimension\r\n",
        "    dec_dim (int): decoding dimension\r\n",
        "    rec_mod (string): type of recurrent modules // 'biLSTM' or 'GRU'\r\n",
        "    bert_ft (boolean): whether or not the bert will be fine - tuned\r\n",
        "    dropout (boolean): whether or not using the dropout\r\n",
        "    drop_prob (double): dropout probability\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # use pre - trained BERT for creating the embeddings\r\n",
        "    bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\r\n",
        "    if not bert_ft:\r\n",
        "      for layer in bert_model.layers:\r\n",
        "        layer.trainable = False\r\n",
        "\r\n",
        "    # input\r\n",
        "    input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32)\r\n",
        "    token_type_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32)\r\n",
        "    attention_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32)\r\n",
        "    embeddings = bert_model(\r\n",
        "        input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask\r\n",
        "    )[0]\r\n",
        "\r\n",
        "\r\n",
        "    if enc_dec: # model with encoder - decoder\r\n",
        "\r\n",
        "\r\n",
        "      if rec_mod == 'biLSTM':\r\n",
        "\r\n",
        "        encoder = layers.Bidirectional(layers.LSTM(enc_dim, return_sequences = True), \r\n",
        "                                          merge_mode = 'concat')(embeddings)\r\n",
        "\r\n",
        "        decoder = layers.Bidirectional(layers.LSTM(dec_dim, return_sequences = True), \r\n",
        "                                                      merge_mode = 'concat')(encoder)\r\n",
        "\r\n",
        "        high_dim = dec_dim*2 # number of units of the dense layers of the highway network\r\n",
        "\r\n",
        "    \r\n",
        "      else:\r\n",
        "\r\n",
        "        encoder = layers.GRU(enc_dim, return_sequences = True)(embeddings)\r\n",
        "\r\n",
        "        decoder = layers.GRU(dec_dim, return_sequences = True)(encoder)\r\n",
        "\r\n",
        "        high_dim = dec_dim\r\n",
        "\r\n",
        "\r\n",
        "      # highway network\r\n",
        "      x_proj = layers.Dense(units = high_dim, activation = 'relu')(decoder)\r\n",
        "      x_gate = layers.Dense(units = high_dim, activation = 'sigmoid')(decoder)\r\n",
        "\r\n",
        "      x = (x_proj * x_gate) + (1 - x_gate) * decoder\r\n",
        "    \r\n",
        "\r\n",
        "    else: # base model\r\n",
        "\r\n",
        "      x = embeddings\r\n",
        "\r\n",
        "    # dropout\r\n",
        "    if dropout:\r\n",
        "      x = layers.Dropout(drop_prob)(x)\r\n",
        "\r\n",
        "    # output\r\n",
        "\r\n",
        "    start_logits = layers.Dense(1, use_bias = False)(x)\r\n",
        "    start_logits = layers.Flatten()(start_logits)\r\n",
        "\r\n",
        "    end_logits = layers.Dense(1, use_bias = False)(x)\r\n",
        "    end_logits = layers.Flatten()(end_logits)\r\n",
        "\r\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\r\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\r\n",
        "\r\n",
        "\r\n",
        "    model = keras.Model(\r\n",
        "        inputs = [input_ids, token_type_ids, attention_mask],\r\n",
        "        outputs = [start_probs, end_probs]\r\n",
        "    )\r\n",
        "\r\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = False)\r\n",
        "    optimizer = keras.optimizers.Adam(lr = 5e-5)\r\n",
        "    model.compile(optimizer = optimizer, loss = [loss, loss])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOkcMBHzGWA_"
      },
      "source": [
        "rec_mod = 'GRU'\r\n",
        "ft = True\r\n",
        "dropout = True\r\n",
        "drop_prob = 0.5\r\n",
        "\r\n",
        "\r\n",
        "use_tpu = True\r\n",
        "if use_tpu:\r\n",
        "    # Create distribution strategy\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "\r\n",
        "    # Create model\r\n",
        "    with strategy.scope():\r\n",
        "        #model = create_model(enc_dec = False, dropout = True, drop_prob = 0.5)\r\n",
        "        model = create_model(enc_dec = True, rec_mod = rec_mod, bert_ft = ft, \r\n",
        "                              dropout = dropout, drop_prob = drop_prob)\r\n",
        "else:\r\n",
        "    model = create_model(enc_dec = True, rec_mod = rec_mod, bert_ft = ft, \r\n",
        "                          dropout = dropout, drop_prob = drop_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qyPZRDbWqa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44YHPxAzL4uH"
      },
      "source": [
        "## Create evaluation Callback\r\n",
        "\r\n",
        "This callback will compute the exact match score using the validation data\r\n",
        "after every epoch.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75z_-Z3iZlwv"
      },
      "source": [
        "def normalize_text(text):\r\n",
        "    text = text.lower()\r\n",
        "\r\n",
        "    # Remove punctuations\r\n",
        "    exclude = set(string.punctuation)\r\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    # Remove articles\r\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\r\n",
        "    text = re.sub(regex, \" \", text)\r\n",
        "\r\n",
        "    # Remove extra white space\r\n",
        "    text = \" \".join(text.split())\r\n",
        "    return text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-LvzUW2bQY6"
      },
      "source": [
        "\n",
        "class ExactMatch(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Each `SquadExample` object contains the character level offsets for each token\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\n",
        "    to the tokens between our predicted start and end tokens.\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\n",
        "    We calculate the percentage of data points where the span of text obtained\n",
        "    from model predictions matches one of the ground-truth answers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "          squad_eg = vl_df.iloc[idx]\n",
        "          offsets = squad_eg['tokenized context'].offsets\n",
        "          start = np.argmax(start)\n",
        "          end = np.argmax(end)\n",
        "          if start >= len(offsets):\n",
        "              continue\n",
        "          pred_char_start = offsets[start][0]\n",
        "          if end < len(offsets):\n",
        "            pred_char_end = offsets[end][1]\n",
        "            pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "          else:\n",
        "            pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "          normalized_pred_ans = normalize_text(pred_ans)\n",
        "          normalized_true_ans = normalize_text(squad_eg['text'])\n",
        "          #normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
        "          #if normalized_pred_ans in normalized_true_ans:\n",
        "          if normalized_pred_ans == normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch = {epoch+1}, exact match score = {acc:.2f}\")\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24aY5QQbboAN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUTb0el4bQY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c209c0ab-8d89-448f-e706-6b0b58b39786"
      },
      "source": [
        "# weights path\n",
        "filepath = '/content/gdrive/My Drive/Colab Notebooks/bert_encDec_weights.h5'\n",
        "\n",
        "# checkpoint callback \n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = filepath,\n",
        "        save_weights_only = True,\n",
        "        )\n",
        "\n",
        "exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 1,\n",
        "    verbose = 1,\n",
        "    batch_size = 256,\n",
        "    callbacks = [exact_match_callback, checkpoint],\n",
        ")\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  6/267 [..............................] - ETA: 2:38 - loss: 10.9006 - activation_2_loss: 5.5891 - activation_3_loss: 5.3114WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 9.0992s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 9.0992s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "267/267 [==============================] - 280s 758ms/step - loss: 4.5841 - activation_2_loss: 2.3616 - activation_3_loss: 2.2225\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 1, exact match score = 0.62\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f747373b690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0yFLYWbb2Pf"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msdw2-Amgysq",
        "outputId": "6e2a17c3-bcea-4ac4-e1f4-504aac56611b"
      },
      "source": [
        "! git clone https://github.com/amrlnic/SQuAD.git"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SQuAD' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOrunjMib4xH"
      },
      "source": [
        "predictions = model.predict(x_eval) \r\n",
        "\r\n",
        "predictions2 = {}\r\n",
        "for i in range(len(predictions[0])):\r\n",
        "  start=np.argmax(predictions[0][i])\r\n",
        "  end=np.argmax(predictions[1][i])\r\n",
        "  tokenized_answer = x_eval[0][i:i+1][0][start:end+1]\r\n",
        "\r\n",
        "  decoded = tokenizer.decode(tokenized_answer)\r\n",
        "\r\n",
        "  predictions2[vl_df.iloc[i]['index']] = decoded\r\n",
        "\r\n",
        "##### Save model predictions on val set as a .JSON file  #####\r\n",
        "\r\n",
        "import json\r\n",
        "\r\n",
        "with open('pred.json', 'w') as fp:\r\n",
        "    json.dump(predictions2, fp)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySWMq7wpcyaF",
        "outputId": "cf739e32-b070-4ca8-ef20-39c68e2a9389"
      },
      "source": [
        "!python3 SQuAD/evaluation/evaluate.py SQuAD/BERT/BERT_valid_set.json pred.json"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 55.482298188265275,\n",
            "  \"f1\": 70.70630423648977,\n",
            "  \"total\": 18049,\n",
            "  \"HasAns_exact\": 55.482298188265275,\n",
            "  \"HasAns_f1\": 70.70630423648977,\n",
            "  \"HasAns_total\": 18049\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}