{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14/03_final_preprocessing_for_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQRVZ0vWQlkl"
      },
      "source": [
        "Importing of GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF3WYL5YQlBF",
        "outputId": "784d686d-ad63-4da9-d9bc-956bcedbbb92"
      },
      "source": [
        "! git clone https://github.com/amrlnic/SQuAD.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SQuAD' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpRypFIUQAm7"
      },
      "source": [
        "Importing of necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7d9iWg2P5Xp",
        "outputId": "4b9edae8-bfb7-4074-ac57-3a9ad5c5aa67"
      },
      "source": [
        "import json\r\n",
        "import os\r\n",
        "import io\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import nltk\r\n",
        "from nltk import word_tokenize\r\n",
        "nltk.download('punkt')\r\n",
        "import gensim.downloader as gloader\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import re\r\n",
        "import pickle\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84Dvlw4vQJaH"
      },
      "source": [
        "Glove download function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlQPtkeTQJDG"
      },
      "source": [
        "EMBEDDING_SIZE = 300\r\n",
        "\r\n",
        "def download_glove_model(embedding_dimension = 50):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  download glove model\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\r\n",
        "  try:\r\n",
        "    print('[INFO] downloading glove {}'.format(embedding_dimension))\r\n",
        "    emb_model = gloader.load(download_path)\r\n",
        "    print('[INFO] done !')\r\n",
        "  except ValueError as e:\r\n",
        "      print(\"Glove: 50, 100, 200, 300\")\r\n",
        "      raise e\r\n",
        "  return emb_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTxbU0RuRMFv"
      },
      "source": [
        "Extracting the dataset from the GitHub folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxFMkprNQSnA",
        "outputId": "08b51542-d9d9-42af-a0e2-1389ec28c4b9"
      },
      "source": [
        "\r\n",
        "with open(\"SQuAD/data/training_set.json\") as f:\r\n",
        "    data = json.load(f)\r\n",
        "\r\n",
        "\r\n",
        "def load_dataset(file, record_path = ['data', 'paragraphs', 'qas', 'answers'], verbose = True):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the SQUAD dataset into a dataframe\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"Reading the json file\")\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "      print(\"[INFO] processing...\")\r\n",
        "\r\n",
        "  # parsing different level's in the json file\r\n",
        "  js = pd.json_normalize(file , record_path )\r\n",
        "  m = pd.json_normalize(file, record_path[:-1] )\r\n",
        "  r = pd.json_normalize(file, record_path[:-2])\r\n",
        "  t = pd.json_normalize(file, record_path[0])\r\n",
        "\r\n",
        "  title = pd.json_normalize(file['data'], record_path = ['paragraphs'], meta = 'title')\r\n",
        "\r\n",
        "  #combining it into single dataframe\r\n",
        "  idx = np.repeat(r['context'].values, r.qas.str.len())\r\n",
        "  ndx  = np.repeat(m['id'].values, m['answers'].str.len())\r\n",
        "  m['context'] = idx\r\n",
        "  m['title'] = np.repeat(title['title'].values, r.qas.str.len())\r\n",
        "  js['q_idx'] = ndx\r\n",
        "  main = pd.concat([ m[['id','question','context', 'title']].set_index('id'), js.set_index('q_idx')], 1, sort = False).reset_index()\r\n",
        "  main['c_id'] = main['context'].factorize()[0]\r\n",
        "  if verbose:\r\n",
        "      print(f\"[INFO] there are {main.shape[0]} questions with single answer\")\r\n",
        "      print(f\"[INFO] there are {main.groupby('c_id').sum().shape[0]} different contexts\")\r\n",
        "      print(f\"[INFO] there are {len(t)} unrelated subjects\")\r\n",
        "      print(\"[INFO] Done\")\r\n",
        "  return main\r\n",
        "\r\n",
        "squad_dataset = load_dataset(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the json file\n",
            "[INFO] processing...\n",
            "[INFO] there are 87599 questions with single answer\n",
            "[INFO] there are 18891 different contexts\n",
            "[INFO] there are 442 unrelated subjects\n",
            "[INFO] Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHJipywrRScg"
      },
      "source": [
        "Examining the head of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "OM0cjfykRVW7",
        "outputId": "90c9b67b-78d9-4c3c-bf44-980fa5598bf2"
      },
      "source": [
        "squad_dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>188</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ... c_id\n",
              "0  5733be284776f41900661182  ...    0\n",
              "1  5733be284776f4190066117f  ...    0\n",
              "2  5733be284776f41900661180  ...    0\n",
              "3  5733be284776f41900661181  ...    0\n",
              "4  5733be284776f4190066117e  ...    0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qSI6A87RZ9n"
      },
      "source": [
        "SAMPLES = squad_dataset.shape[0]\r\n",
        "\r\n",
        "#---lowercase and strip the given text---#\r\n",
        "def preprocess_sentence(text): \r\n",
        "  text = text.lower()\r\n",
        "  text = text.strip()\r\n",
        "  return text\r\n",
        "#----------------------------------------#\r\n",
        "\r\n",
        "#---preprocess the dataset---------------#\r\n",
        "def clean_dataset(dataset):\r\n",
        "\r\n",
        "  _dataset = dataset.copy()\r\n",
        "\r\n",
        "  cleaned_questions = _dataset['question'].apply(preprocess_sentence)\r\n",
        "  cleaned_texts = _dataset['text'].apply(preprocess_sentence)\r\n",
        "\r\n",
        "#---we process only different contexts and then we duplicate them---#\r\n",
        "  unique_context = pd.Series(_dataset['context'].unique())\r\n",
        "  count_c = _dataset.groupby('c_id').count()['text']\r\n",
        "  cleaned_contexts = unique_context.apply(preprocess_sentence)\r\n",
        "\r\n",
        "  _dataset['question'] = cleaned_questions\r\n",
        "  _dataset['text'] = cleaned_texts\r\n",
        "  _dataset['context'] = pd.Series(np.repeat(cleaned_contexts, count_c).tolist())\r\n",
        "\r\n",
        "  return _dataset\r\n",
        "#----------------------------------------#\r\n",
        "squad_dataset = clean_dataset(squad_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_6afw02K9f"
      },
      "source": [
        "Train and validation datasets creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br8kV3Wv2LbA"
      },
      "source": [
        "def get_tokenizer(dataset, glove_model = None):\r\n",
        "\r\n",
        "\r\n",
        "#----create the word and char tokenizer and feed them on the given dataset----#\r\n",
        "\r\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = 'UNK', filters = '')\r\n",
        "\r\n",
        "  # we will only keep the 200 - 1 most frequent characters (otherwise oom issue)\r\n",
        "  # others tokens are replaced by UNK token \r\n",
        "  # we keep 199 most frequent tokens and indice 1 is UNK token (so we keep 198 tokens)\r\n",
        "\r\n",
        "  char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level = True, filters = '', oov_token = 'UNK', num_words = 200)\r\n",
        "\r\n",
        "  if glove_model == None:\r\n",
        "    glove_model = download_glove_model(EMBEDDING_SIZE)\r\n",
        "\r\n",
        "  tokenized_questions = dataset['question'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  contexts = pd.Series(dataset['context'].unique())\r\n",
        "  tokenized_contexts = contexts.apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  sequences = glove_model.index2entity + tokenized_questions + tokenized_contexts\r\n",
        "\r\n",
        "  del glove_model # we  don't need anymore the glove model\r\n",
        "\r\n",
        "  tokenizer.fit_on_texts(sequences)\r\n",
        "  char_tokenizer.fit_on_texts(dataset['question'].to_list() + contexts.to_list())\r\n",
        "\r\n",
        "  return tokenizer, char_tokenizer\r\n",
        "\r\n",
        "\r\n",
        "def update_tokenizer(dataset, tokenizer, char_tokenizer):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  update the existing word/char vocabulary on a new dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  tokenized_questions = dataset['question'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  contexts = pd.Series(dataset['context'].unique())\r\n",
        "  tokenized_contexts = contexts.apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  sequences = tokenized_questions + tokenized_contexts\r\n",
        "  tokenizer.fit_on_texts(sequences)\r\n",
        "\r\n",
        "  char_tokenizer.fit_on_texts(dataset['question'].to_list() + contexts.to_list())\r\n",
        "\r\n",
        "def get_start_end(row):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  get the start and end span for each sample,\r\n",
        "  if the span cannot be found return -1\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  context = row['context']\r\n",
        "  answer = row['text']\r\n",
        "  tok_answer = word_tokenize(answer)\r\n",
        "\r\n",
        "  _start = context.find(answer)\r\n",
        "\r\n",
        "  if _start == -1:\r\n",
        "    # the answer is not in the context\r\n",
        "    # maybe due to a typo\r\n",
        "    row['start'] = -1\r\n",
        "    row['end'] = -1\r\n",
        "    return row\r\n",
        "\r\n",
        "  lc = context[:_start]\r\n",
        "  lc = word_tokenize(lc)\r\n",
        "\r\n",
        "  start = len(lc)\r\n",
        "  end = start + len(tok_answer)\r\n",
        "\r\n",
        "  row['start'] = start\r\n",
        "  row['end'] = end\r\n",
        "\r\n",
        "  return row\r\n",
        "\r\n",
        "def tokenize(dataset, tokenizer, char_tokenizer):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  tokenize the given dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  _dataset = dataset.copy()\r\n",
        "\r\n",
        "  tokenized_questions = _dataset['question'].apply(word_tokenize).to_list()\r\n",
        "  tokenized_contexts = _dataset['context'].apply(word_tokenize).to_list()\r\n",
        "\r\n",
        "  t_q = tokenizer.texts_to_sequences(tokenized_questions)\r\n",
        "  t_c = tokenizer.texts_to_sequences(tokenized_contexts)\r\n",
        "\r\n",
        "  c_q = []\r\n",
        "  c_c = []\r\n",
        "\r\n",
        "  for question, context in zip(tokenized_questions, tokenized_contexts):\r\n",
        "    _q = char_tokenizer.texts_to_sequences(question)\r\n",
        "    _c = char_tokenizer.texts_to_sequences(context)\r\n",
        "    c_q.append(_q)\r\n",
        "    c_c.append(_c)\r\n",
        "\r\n",
        "  _dataset['tokenized_question'] = t_q\r\n",
        "  _dataset['tokenized_context'] = t_c\r\n",
        "\r\n",
        "  _dataset['char_tokenized_question'] = c_q\r\n",
        "  _dataset['char_tokenized_context'] = c_c\r\n",
        "\r\n",
        "  return _dataset\r\n",
        "\r\n",
        "def split(dataset, test_size = 0.2, random_state = 42):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  split the dataset in two part: the training and the validation\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # random_state for deterministic state\r\n",
        "  tr, vl = train_test_split(dataset, test_size = test_size, random_state = random_state)\r\n",
        "  tr.reset_index(drop = True, inplace = True)\r\n",
        "  vl.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  return tr,vl\r\n",
        "\r\n",
        "def df_to_json(df, path):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  parse the given dataframe into the SQUAD json format\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  data = []\r\n",
        "\r\n",
        "  for title, articles in df.groupby('title'):\r\n",
        "    chapter = {'title': title}\r\n",
        "    paragraphs = []\r\n",
        "    for context, contents in articles.groupby('context'):\r\n",
        "      paragraph = {'context': context}\r\n",
        "      qas = []\r\n",
        "      for i, content in contents.iterrows():\r\n",
        "        qa = {'answers': [{'answer_start': content['answer_start'], 'text': content['text']}], 'question': content['question'], 'id': content['index']}\r\n",
        "        qas.append(qa)\r\n",
        "      paragraph.update({'qas': qas})\r\n",
        "      paragraphs.append(paragraph)\r\n",
        "    chapter.update({'paragraphs': paragraphs})\r\n",
        "    data.append(chapter)\r\n",
        "  raw_data = {'data': data}\r\n",
        "\r\n",
        "  with open(path, 'w') as handle:\r\n",
        "    json.dump(raw_data, handle)\r\n",
        "\r\n",
        "  print(f'dataset saved in {path}')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IsSzgdq2ckb",
        "outputId": "32e867f3-b2e7-4b64-be2e-be36322615d3"
      },
      "source": [
        "tr_df, vl_df = split(squad_dataset)\r\n",
        "tr_df.shape[0],vl_df.shape[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70079, 17520)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FljF_n7s2qnT"
      },
      "source": [
        "Our vocabulary is based on the Glove vocabulary, and we add terms from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSVCOPmX2rWI",
        "outputId": "d67c8a63-e017-4a63-964e-f45f7c2c5589"
      },
      "source": [
        "tokenizer, char_tokenizer = get_tokenizer(tr_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] downloading glove 300\n",
            "[INFO] done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR6nXbZK2xRp",
        "outputId": "443a30de-e3c2-490c-dc0b-8a15330b4154"
      },
      "source": [
        "print(len(tokenizer.word_index))\r\n",
        "len(char_tokenizer.word_index)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "429064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKuOAKq20ED"
      },
      "source": [
        "We then update our vocabulary with terms from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZREgrEN2zYS",
        "outputId": "40e2d416-c275-4f7e-b54e-f99d48a14ae5"
      },
      "source": [
        "update_tokenizer(vl_df, tokenizer, char_tokenizer)\r\n",
        "print(len(tokenizer.word_index))\r\n",
        "len(char_tokenizer.word_index)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "429758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKyjfmKB25Y0"
      },
      "source": [
        "Training and validation datasets update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxMoUYJl24z_"
      },
      "source": [
        "# take a while\r\n",
        "tr_df = tr_df.apply(get_start_end, axis = 1)\r\n",
        "vl_df = vl_df.apply(get_start_end, axis = 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRFSZkD_2-od"
      },
      "source": [
        "we get rid of samples where the answer doesn't match the context (maybe there is a typo in the answer or the context).  \r\n",
        "To avoid to discard many samples, we could lemmatize / stem the text.   \r\n",
        "Obviously, lemmatization is a better choice for our task, but if we want a really accurate lemmatization processing, we need to do POS tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4cpviH32_R8",
        "outputId": "f5485dea-e165-4249-c60c-eaf6cee4f891"
      },
      "source": [
        "tr_df[tr_df['start'] == -1].shape[0], vl_df[vl_df['start'] == -1].shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "OwrGp1yZ3BRv",
        "outputId": "33b39203-5e3c-49db-da4d-07f0469cccbd"
      },
      "source": [
        "tr_df[tr_df['start'] == -1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>56de31984396321400ee2672</td>\n",
              "      <td>on what date was the 2013 human development re...</td>\n",
              "      <td>some countries were not included for various r...</td>\n",
              "      <td>Human_Development_Index</td>\n",
              "      <td>92</td>\n",
              "      <td>march 14, 2013</td>\n",
              "      <td>2185</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>56e17f5de3433e1400422f8c</td>\n",
              "      <td>what field studies the placement of catalan in...</td>\n",
              "      <td>in central catalan, unstressed vowels reduce t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>0</td>\n",
              "      <td>catalan sociolinguistics</td>\n",
              "      <td>3470</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3983</th>\n",
              "      <td>56e1b97fcd28a01900c67ad8</td>\n",
              "      <td>what is the official regulating body of  valen...</td>\n",
              "      <td>valencian is classified as a western dialect, ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>168</td>\n",
              "      <td>the valencian academy of language</td>\n",
              "      <td>3488</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6198</th>\n",
              "      <td>56e1b4decd28a01900c67a91</td>\n",
              "      <td>what language is the regulator meant to standa...</td>\n",
              "      <td>in alghero, the iec has adapted its standard t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>103</td>\n",
              "      <td>catalan</td>\n",
              "      <td>3486</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6994</th>\n",
              "      <td>56e1b738cd28a01900c67aae</td>\n",
              "      <td>where are the provinces of lleida and tarragona?</td>\n",
              "      <td>in 2011, the aragonese government passed a dec...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>94</td>\n",
              "      <td>western catalonia</td>\n",
              "      <td>3487</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66889</th>\n",
              "      <td>572e8003c246551400ce425f</td>\n",
              "      <td>what did great britain gain in the west indies...</td>\n",
              "      <td>many middle and small powers in europe, unlike...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>113</td>\n",
              "      <td>some individual caribbean islands in the west ...</td>\n",
              "      <td>15282</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66972</th>\n",
              "      <td>572e81f2cb0c0d14000f1206</td>\n",
              "      <td>what is the precedent for the \"second hundred ...</td>\n",
              "      <td>the war was successful for great britain, whic...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>446</td>\n",
              "      <td>reminiscent of the more famous and compact str...</td>\n",
              "      <td>15283</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67376</th>\n",
              "      <td>572e8578c246551400ce42bd</td>\n",
              "      <td>who would sicily and savoy normally align with?</td>\n",
              "      <td>realizing that war was imminent, prussia preem...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>434</td>\n",
              "      <td>sicily, and savoy, although sided with franco-...</td>\n",
              "      <td>15281</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69867</th>\n",
              "      <td>56e180f5e3433e1400422f96</td>\n",
              "      <td>what do the dialects of catalan feature?</td>\n",
              "      <td>catalan sociolinguistics studies the situation...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>56</td>\n",
              "      <td>uniformity</td>\n",
              "      <td>3471</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69923</th>\n",
              "      <td>56e17f5de3433e1400422f90</td>\n",
              "      <td>what outside affects does this study include?</td>\n",
              "      <td>in central catalan, unstressed vowels reduce t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>331</td>\n",
              "      <td>other languages in contact</td>\n",
              "      <td>3470</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ... end\n",
              "87     56de31984396321400ee2672  ...  -1\n",
              "3133   56e17f5de3433e1400422f8c  ...  -1\n",
              "3983   56e1b97fcd28a01900c67ad8  ...  -1\n",
              "6198   56e1b4decd28a01900c67a91  ...  -1\n",
              "6994   56e1b738cd28a01900c67aae  ...  -1\n",
              "...                         ...  ...  ..\n",
              "66889  572e8003c246551400ce425f  ...  -1\n",
              "66972  572e81f2cb0c0d14000f1206  ...  -1\n",
              "67376  572e8578c246551400ce42bd  ...  -1\n",
              "69867  56e180f5e3433e1400422f96  ...  -1\n",
              "69923  56e17f5de3433e1400422f90  ...  -1\n",
              "\n",
              "[69 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pmOonLxX3FTn",
        "outputId": "47ad988d-017c-4b3a-dea2-793a40df6dda"
      },
      "source": [
        "vl_df[vl_df['start'] == -1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>56e18a90e3433e1400422fac</td>\n",
              "      <td>in what densely populated area is it spoken?</td>\n",
              "      <td>western catalan comprises the two dialects of ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>166</td>\n",
              "      <td>barcelona province</td>\n",
              "      <td>3474</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>56e1a3cbe3433e1400423066</td>\n",
              "      <td>where is iec's standard used?</td>\n",
              "      <td>standard catalan, virtually accepted by all sp...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>3</td>\n",
              "      <td>the balearic islands</td>\n",
              "      <td>3484</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3007</th>\n",
              "      <td>56e18710cd28a01900c679b9</td>\n",
              "      <td>what have a and e done in eastern dialects?</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>162</td>\n",
              "      <td>merged</td>\n",
              "      <td>3472</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4925</th>\n",
              "      <td>56e1b4decd28a01900c67a8e</td>\n",
              "      <td>where is the catalan speaking part of aragon?</td>\n",
              "      <td>in alghero, the iec has adapted its standard t...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>114</td>\n",
              "      <td>la franja</td>\n",
              "      <td>3486</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5782</th>\n",
              "      <td>56e18bfbe3433e1400422fb5</td>\n",
              "      <td>how many stressed phonemes are there in catalan?</td>\n",
              "      <td>central catalan is considered the standard pro...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>69</td>\n",
              "      <td>seven</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5897</th>\n",
              "      <td>56e18710cd28a01900c679b7</td>\n",
              "      <td>what is the major difference between the two b...</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>118</td>\n",
              "      <td>treatment of unstressed a and e</td>\n",
              "      <td>3472</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5937</th>\n",
              "      <td>56e18bfbe3433e1400422fb4</td>\n",
              "      <td>what is the vowel system of catalan?</td>\n",
              "      <td>western catalan comprises the two dialects of ...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>50</td>\n",
              "      <td>vulgar latin</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6561</th>\n",
              "      <td>56e1b264e3433e14004230a6</td>\n",
              "      <td>where has the iec adapted its standard to the ...</td>\n",
              "      <td>the most notable difference between both stand...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>3</td>\n",
              "      <td>alghero</td>\n",
              "      <td>3485</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7378</th>\n",
              "      <td>572e81f2cb0c0d14000f1207</td>\n",
              "      <td>what was a later conflict that some considered...</td>\n",
              "      <td>the war was successful for great britain, whic...</td>\n",
              "      <td>Seven_Years%27_War</td>\n",
              "      <td>246</td>\n",
              "      <td>to later conflicts like the napoleonic wars</td>\n",
              "      <td>15283</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11252</th>\n",
              "      <td>56e17b08cd28a01900c679af</td>\n",
              "      <td>where do you find dialectic vowel reductions?</td>\n",
              "      <td>catalan has inherited the typical vowel system...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>176</td>\n",
              "      <td>section pronunciation</td>\n",
              "      <td>3469</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11511</th>\n",
              "      <td>56de31f34396321400ee2680</td>\n",
              "      <td>does the ihdi measure the \"average\" or the \"po...</td>\n",
              "      <td>the 2013 human development report by the unite...</td>\n",
              "      <td>Human_Development_Index</td>\n",
              "      <td>72</td>\n",
              "      <td>the average level</td>\n",
              "      <td>2182</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12438</th>\n",
              "      <td>56e188e4cd28a01900c679c0</td>\n",
              "      <td>how many dialects are in the eastern group?</td>\n",
              "      <td>the dialects of the catalan language feature a...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>110</td>\n",
              "      <td>four</td>\n",
              "      <td>3473</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16218</th>\n",
              "      <td>56e180f5e3433e1400422f97</td>\n",
              "      <td>in comparison to what are the dialects uniform?</td>\n",
              "      <td>catalan sociolinguistics studies the situation...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>96</td>\n",
              "      <td>other romance languages</td>\n",
              "      <td>3471</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16474</th>\n",
              "      <td>56e1b738cd28a01900c67aaf</td>\n",
              "      <td>what forms are mutually intelligible?</td>\n",
              "      <td>in 2011, the aragonese government passed a dec...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>190</td>\n",
              "      <td>catalan and valencian</td>\n",
              "      <td>3487</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17282</th>\n",
              "      <td>56e18bfbe3433e1400422fb6</td>\n",
              "      <td>where is this system common?</td>\n",
              "      <td>central catalan is considered the standard pro...</td>\n",
              "      <td>Catalan_language</td>\n",
              "      <td>131</td>\n",
              "      <td>western romance</td>\n",
              "      <td>3468</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ... end\n",
              "171    56e18a90e3433e1400422fac  ...  -1\n",
              "1536   56e1a3cbe3433e1400423066  ...  -1\n",
              "3007   56e18710cd28a01900c679b9  ...  -1\n",
              "4925   56e1b4decd28a01900c67a8e  ...  -1\n",
              "5782   56e18bfbe3433e1400422fb5  ...  -1\n",
              "5897   56e18710cd28a01900c679b7  ...  -1\n",
              "5937   56e18bfbe3433e1400422fb4  ...  -1\n",
              "6561   56e1b264e3433e14004230a6  ...  -1\n",
              "7378   572e81f2cb0c0d14000f1207  ...  -1\n",
              "11252  56e17b08cd28a01900c679af  ...  -1\n",
              "11511  56de31f34396321400ee2680  ...  -1\n",
              "12438  56e188e4cd28a01900c679c0  ...  -1\n",
              "16218  56e180f5e3433e1400422f97  ...  -1\n",
              "16474  56e1b738cd28a01900c67aaf  ...  -1\n",
              "17282  56e18bfbe3433e1400422fb6  ...  -1\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2DTxTXdWzQA",
        "outputId": "5d90b7b7-d1c5-488c-e3b4-a8d030eb0a9a"
      },
      "source": [
        "print(len(tr_df))\r\n",
        "print(len(vl_df))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70079\n",
            "17520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjNuaBAz3HKr"
      },
      "source": [
        "Now we get rid of samples where the answer doesn't match the context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrOlW31E3Hee"
      },
      "source": [
        "# we get rid of samples where the answer doesn't match the context\r\n",
        "tr_df = tr_df[tr_df['start'] != -1]\r\n",
        "vl_df = vl_df[vl_df['start'] != -1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct92l4_gJM_Y"
      },
      "source": [
        "We also need to eliminate samples where the answer is after the context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LoNxlhqaKdHR",
        "outputId": "52f7e983-ae2a-4acd-9c9d-548365f8205d"
      },
      "source": [
        "test = 20461\r\n",
        "\r\n",
        "\r\n",
        "print(tr_df.iloc[test]['answer_start'])\r\n",
        "print(len(tr_df.iloc[test]['text']))\r\n",
        "print(len(tr_df.iloc[test]['context']))\r\n",
        "print()\r\n",
        "print(tr_df.iloc[test]['text'])\r\n",
        "#print(tr_df.iloc[test]['context'])\r\n",
        "print()\r\n",
        "tr_df.iloc[test][2]\r\n",
        "#tr_df.iloc[test]['answer_start'] + len(tr_df.iloc[test]['text']) >= len(tr_df.iloc[test]['context'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "301\n",
            "67\n",
            "629\n",
            "\n",
            "at least one appointee from the state where the project is to occur\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the question to be answered is whether a listed species will be harmed by the action and, if so, how the harm can be minimized. if harm cannot be avoided, the project agency can seek an exemption from the endangered species committee, an ad hoc panel composed of members from the executive branch and at least one appointee from the state where the project is to occur. five of the seven committee members must vote for the exemption to allow taking (to harass, harm, pursue, hunt, shoot, wound, kill, trap, capture, or collect, or significant habitat modification, or to attempt to engage in any such conduct) of listed species.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnqW4VzvJXLL"
      },
      "source": [
        "#tr_df[ tr_df['answer_start'] + len(tr_df['text']) >= len(tr_df['context']) ]\r\n",
        "#tr_df['answer_start'] + len(tr_df['text']) >= len(tr_df['context']) \r\n",
        "tr_mask = np.array([ tr_df.iloc[k]['answer_start'] + len(tr_df.iloc[k]['text']) < len(tr_df.iloc[k]['context']) for k in range(len(tr_df)) ])\r\n",
        "vl_mask = np.array([ vl_df.iloc[k]['answer_start'] + len(vl_df.iloc[k]['text']) < len(vl_df.iloc[k]['context']) for k in range(len(vl_df)) ])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qvhO6fZOMVW-",
        "outputId": "5f24af1d-5f5a-4122-8afe-ed1d8a052b43"
      },
      "source": [
        "#debug window\r\n",
        "\"\"\"\r\n",
        "tr_df[ mask ].iloc[0]['answer_start'] + len(tr_df[mask].iloc[0]['text'])\r\n",
        "print(tr_df[ mask ].iloc[0]['answer_start'])\r\n",
        "print(tr_df[mask].iloc[0]['text'])\r\n",
        "print(len(tr_df[mask].iloc[0]['text']))\r\n",
        "print(tr_df[mask].iloc[0]['context'])\r\n",
        "print(len(tr_df[mask].iloc[0]['context']))\r\n",
        "print()\r\n",
        "print(tr_df[mask].iloc[0]['context'][195:])\r\n",
        "\"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntr_df[ mask ].iloc[0]['answer_start'] + len(tr_df[mask].iloc[0]['text'])\\nprint(tr_df[ mask ].iloc[0]['answer_start'])\\nprint(tr_df[mask].iloc[0]['text'])\\nprint(len(tr_df[mask].iloc[0]['text']))\\nprint(tr_df[mask].iloc[0]['context'])\\nprint(len(tr_df[mask].iloc[0]['context']))\\nprint()\\nprint(tr_df[mask].iloc[0]['context'][195:])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "7xQxa_HsWpVn",
        "outputId": "1125723a-2162-497b-c876-922cb1c9b802"
      },
      "source": [
        "tr_df[tr_mask]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572667e6708984140094c4f9</td>\n",
              "      <td>what team had dallas green managed in 1980?</td>\n",
              "      <td>after over a dozen more subpar seasons, in 198...</td>\n",
              "      <td>Chicago_Cubs</td>\n",
              "      <td>154</td>\n",
              "      <td>phillies</td>\n",
              "      <td>8880</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56dec2483277331400b4d712</td>\n",
              "      <td>which candidate withdrew from the presidential...</td>\n",
              "      <td>schwarzenegger's endorsement in the republican...</td>\n",
              "      <td>Arnold_Schwarzenegger</td>\n",
              "      <td>156</td>\n",
              "      <td>rudy giuliani</td>\n",
              "      <td>2311</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5726e5995951b619008f81bb</td>\n",
              "      <td>captive animals can distinguish co-inhabitats ...</td>\n",
              "      <td>it has been observed that well-fed predator an...</td>\n",
              "      <td>Predation</td>\n",
              "      <td>224</td>\n",
              "      <td>wild ones outside the area</td>\n",
              "      <td>9822</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5726486f708984140094c157</td>\n",
              "      <td>the results of which battle allowed the britis...</td>\n",
              "      <td>after returning from egypt, napoleon engineere...</td>\n",
              "      <td>Napoleon</td>\n",
              "      <td>919</td>\n",
              "      <td>the battle of trafalgar</td>\n",
              "      <td>8418</td>\n",
              "      <td>158</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5730299db2c2fd14005689a7</td>\n",
              "      <td>how was vesey executed in 1822?</td>\n",
              "      <td>by 1820, charleston's population had grown to ...</td>\n",
              "      <td>Charleston,_South_Carolina</td>\n",
              "      <td>382</td>\n",
              "      <td>hanged</td>\n",
              "      <td>15719</td>\n",
              "      <td>74</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70073</th>\n",
              "      <td>57320f26e17f3d1400422651</td>\n",
              "      <td>where do male emporer penguins keep eggs?</td>\n",
              "      <td>bird eggs are usually laid in a nest. most spe...</td>\n",
              "      <td>Bird</td>\n",
              "      <td>730</td>\n",
              "      <td>between their body and feet</td>\n",
              "      <td>17809</td>\n",
              "      <td>136</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70074</th>\n",
              "      <td>56d12d3c17492d1400aabb6b</td>\n",
              "      <td>on what day did the final coroner's report sho...</td>\n",
              "      <td>adams sent condolences to donda west's family ...</td>\n",
              "      <td>Kanye_West</td>\n",
              "      <td>640</td>\n",
              "      <td>january 10, 2008</td>\n",
              "      <td>1082</td>\n",
              "      <td>117</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70075</th>\n",
              "      <td>5727c461ff5b5019007d94b1</td>\n",
              "      <td>in which u.s. state was the oldest definitive ...</td>\n",
              "      <td>tuberculosis has been present in humans since ...</td>\n",
              "      <td>Tuberculosis</td>\n",
              "      <td>171</td>\n",
              "      <td>wyoming</td>\n",
              "      <td>11805</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70076</th>\n",
              "      <td>57343f804776f41900661afa</td>\n",
              "      <td>what major cities later adopted tucson's city ...</td>\n",
              "      <td>tucson is known for being a trailblazer in vol...</td>\n",
              "      <td>Tucson,_Arizona</td>\n",
              "      <td>757</td>\n",
              "      <td>san francisco and new york city</td>\n",
              "      <td>16641</td>\n",
              "      <td>145</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70077</th>\n",
              "      <td>56bec9f13aeaaa14008c9467</td>\n",
              "      <td>which rock band cited beyonce on their third a...</td>\n",
              "      <td>beyoncÃ©'s work has influenced numerous artists...</td>\n",
              "      <td>BeyoncÃ©</td>\n",
              "      <td>292</td>\n",
              "      <td>white rabbits</td>\n",
              "      <td>106</td>\n",
              "      <td>57</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69572 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ...  end\n",
              "0      572667e6708984140094c4f9  ...   30\n",
              "1      56dec2483277331400b4d712  ...   25\n",
              "2      5726e5995951b619008f81bb  ...   43\n",
              "3      5726486f708984140094c157  ...  162\n",
              "4      5730299db2c2fd14005689a7  ...   75\n",
              "...                         ...  ...  ...\n",
              "70073  57320f26e17f3d1400422651  ...  141\n",
              "70074  56d12d3c17492d1400aabb6b  ...  121\n",
              "70075  5727c461ff5b5019007d94b1  ...   28\n",
              "70076  57343f804776f41900661afa  ...  151\n",
              "70077  56bec9f13aeaaa14008c9467  ...   59\n",
              "\n",
              "[69572 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "j8CIK74fSQYd",
        "outputId": "3c030b11-ccce-4f71-f33b-26831b050480"
      },
      "source": [
        "vl_df[vl_mask]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56de4d9ecffd8e1900b4b7e2</td>\n",
              "      <td>what year was the banskÃ¡ akadÃ©mia founded?</td>\n",
              "      <td>the world's first institution of technology or...</td>\n",
              "      <td>Institute_of_technology</td>\n",
              "      <td>167</td>\n",
              "      <td>1735</td>\n",
              "      <td>1860</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>572674a05951b619008f7319</td>\n",
              "      <td>what is another speed that can also be reporte...</td>\n",
              "      <td>the standard specifies how speed ratings shoul...</td>\n",
              "      <td>Film_speed</td>\n",
              "      <td>793</td>\n",
              "      <td>sos-based speed</td>\n",
              "      <td>9354</td>\n",
              "      <td>145</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5730bb058ab72b1400f9c72c</td>\n",
              "      <td>where were the use of advanced materials and t...</td>\n",
              "      <td>the most impressive and famous of sumerian bui...</td>\n",
              "      <td>Sumer</td>\n",
              "      <td>421</td>\n",
              "      <td>sumerian temples and palaces</td>\n",
              "      <td>17505</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>572781a5f1498d1400e8fa1f</td>\n",
              "      <td>who is elected every even numbered year?</td>\n",
              "      <td>ann arbor has a council-manager form of govern...</td>\n",
              "      <td>Ann_Arbor,_Michigan</td>\n",
              "      <td>192</td>\n",
              "      <td>mayor</td>\n",
              "      <td>10585</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>572843ce4b864d190016485c</td>\n",
              "      <td>what was the purpose of top secret icbm commit...</td>\n",
              "      <td>shortly before his death, when he was already ...</td>\n",
              "      <td>John_von_Neumann</td>\n",
              "      <td>194</td>\n",
              "      <td>decide on the feasibility of building an icbm ...</td>\n",
              "      <td>11497</td>\n",
              "      <td>38</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17515</th>\n",
              "      <td>570b4f4dec8fbc190045b976</td>\n",
              "      <td>what country refused to allow forces to stage ...</td>\n",
              "      <td>after the lengthy iraq disarmament crisis culm...</td>\n",
              "      <td>Military_history_of_the_United_States</td>\n",
              "      <td>443</td>\n",
              "      <td>turkey</td>\n",
              "      <td>6586</td>\n",
              "      <td>76</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17516</th>\n",
              "      <td>571a2b2410f8ca1400304f2a</td>\n",
              "      <td>who is the representative for seattle's district?</td>\n",
              "      <td>like most parts of the united states, governme...</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>438</td>\n",
              "      <td>jim mcdermott</td>\n",
              "      <td>7943</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17517</th>\n",
              "      <td>572970803f37b319004783c8</td>\n",
              "      <td>at what temperature to zinc become brittle?</td>\n",
              "      <td>zinc is a bluish-white, lustrous, diamagnetic ...</td>\n",
              "      <td>Zinc</td>\n",
              "      <td>477</td>\n",
              "      <td>210 Â°c</td>\n",
              "      <td>14548</td>\n",
              "      <td>93</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17518</th>\n",
              "      <td>572acb23f75d5e190021fcdb</td>\n",
              "      <td>how expensive was kerry's yacht?</td>\n",
              "      <td>according to the boston herald, dated july 23,...</td>\n",
              "      <td>John_Kerry</td>\n",
              "      <td>94</td>\n",
              "      <td>$7 million</td>\n",
              "      <td>15037</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17519</th>\n",
              "      <td>5726a975708984140094cd39</td>\n",
              "      <td>what italian prime minister attacked montini f...</td>\n",
              "      <td>at the request of the pope, he created an info...</td>\n",
              "      <td>Pope_Paul_VI</td>\n",
              "      <td>343</td>\n",
              "      <td>mussolini</td>\n",
              "      <td>10818</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17394 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          index  ...  end\n",
              "0      56de4d9ecffd8e1900b4b7e2  ...   27\n",
              "1      572674a05951b619008f7319  ...  147\n",
              "2      5730bb058ab72b1400f9c72c  ...   78\n",
              "3      572781a5f1498d1400e8fa1f  ...   19\n",
              "4      572843ce4b864d190016485c  ...   53\n",
              "...                         ...  ...  ...\n",
              "17515  570b4f4dec8fbc190045b976  ...   77\n",
              "17516  571a2b2410f8ca1400304f2a  ...   78\n",
              "17517  572970803f37b319004783c8  ...   95\n",
              "17518  572acb23f75d5e190021fcdb  ...   21\n",
              "17519  5726a975708984140094cd39  ...   63\n",
              "\n",
              "[17394 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YgIYOKCZfeu",
        "outputId": "ae7a951a-d504-495c-a17d-0cfc181aa311"
      },
      "source": [
        "~tr_mask"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhZ9V8N4R8LN"
      },
      "source": [
        "# we get rid of samples where we have answer overflow\r\n",
        "tr_df2 = tr_df[tr_mask] \r\n",
        "vl_df2 = vl_df[vl_mask] "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmt4aenLUVAm",
        "outputId": "7816d4e7-4acb-4249-e656-0199d5b79296"
      },
      "source": [
        "print(len(tr_df2))\r\n",
        "print(len(vl_df2))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69572\n",
            "17394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZdDQLMC3xjd"
      },
      "source": [
        "tr_df2 = tokenize(tr_df2, tokenizer, char_tokenizer)\r\n",
        "vl_df2 = tokenize(vl_df2, tokenizer, char_tokenizer)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OcuGS4H41Ik"
      },
      "source": [
        "Now we explore the cleaned datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "q_vbbGRr3yuK",
        "outputId": "13b73205-f328-4e22-874a-0364d51628cf"
      },
      "source": [
        "tr_df2.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>tokenized_question</th>\n",
              "      <th>tokenized_context</th>\n",
              "      <th>char_tokenized_question</th>\n",
              "      <th>char_tokenized_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572667e6708984140094c4f9</td>\n",
              "      <td>what team had dallas green managed in 1980?</td>\n",
              "      <td>after over a dozen more subpar seasons, in 198...</td>\n",
              "      <td>Chicago_Cubs</td>\n",
              "      <td>154</td>\n",
              "      <td>phillies</td>\n",
              "      <td>8880</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>[11, 309, 49, 11808, 646, 2132, 6, 2627, 9]</td>\n",
              "      <td>[61, 83, 10, 6737, 62, 70020, 1740, 3, 6, 3372...</td>\n",
              "      <td>[[20, 11, 5, 4], [4, 3, 5, 16], [11, 5, 13], [...</td>\n",
              "      <td>[[5, 17, 4, 3, 10], [8, 24, 3, 10], [5], [13, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56dec2483277331400b4d712</td>\n",
              "      <td>which candidate withdrew from the presidential...</td>\n",
              "      <td>schwarzenegger's endorsement in the republican...</td>\n",
              "      <td>Arnold_Schwarzenegger</td>\n",
              "      <td>156</td>\n",
              "      <td>rudy giuliani</td>\n",
              "      <td>2311</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>[27, 2789, 4161, 23, 2, 1534, 698, 6, 417, 4, ...</td>\n",
              "      <td>[1084, 19, 9106, 6, 2, 1467, 477, 4, 2, 420, 1...</td>\n",
              "      <td>[[20, 11, 6, 14, 11], [14, 5, 7, 13, 6, 13, 5,...</td>\n",
              "      <td>[[9, 14, 11, 20, 5, 10, 39, 3, 7, 3, 19, 19, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5726e5995951b619008f81bb</td>\n",
              "      <td>captive animals can distinguish co-inhabitats ...</td>\n",
              "      <td>it has been observed that well-fed predator an...</td>\n",
              "      <td>Predation</td>\n",
              "      <td>224</td>\n",
              "      <td>wild ones outside the area</td>\n",
              "      <td>9822</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "      <td>[11888, 727, 65, 3733, 419169, 23, 11, 48, 136...</td>\n",
              "      <td>[30, 40, 59, 2316, 20, 63225, 4421, 727, 6, 10...</td>\n",
              "      <td>[[14, 5, 18, 4, 6, 24, 3], [5, 7, 6, 16, 5, 12...</td>\n",
              "      <td>[[6, 4], [11, 5, 9], [22, 3, 3, 7], [8, 22, 9,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5726486f708984140094c157</td>\n",
              "      <td>the results of which battle allowed the britis...</td>\n",
              "      <td>after returning from egypt, napoleon engineere...</td>\n",
              "      <td>Napoleon</td>\n",
              "      <td>919</td>\n",
              "      <td>the battle of trafalgar</td>\n",
              "      <td>8418</td>\n",
              "      <td>158</td>\n",
              "      <td>162</td>\n",
              "      <td>[2, 1324, 4, 27, 326, 495, 2, 132, 8, 6280, 15...</td>\n",
              "      <td>[61, 3986, 23, 598, 3, 545, 9789, 10, 2313, 6,...</td>\n",
              "      <td>[[4, 11, 3], [10, 3, 9, 15, 12, 4, 9], [8, 17]...</td>\n",
              "      <td>[[5, 17, 4, 3, 10], [10, 3, 4, 15, 10, 7, 6, 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5730299db2c2fd14005689a7</td>\n",
              "      <td>how was vesey executed in 1822?</td>\n",
              "      <td>by 1820, charleston's population had grown to ...</td>\n",
              "      <td>Charleston,_South_Carolina</td>\n",
              "      <td>382</td>\n",
              "      <td>hanged</td>\n",
              "      <td>15719</td>\n",
              "      <td>74</td>\n",
              "      <td>75</td>\n",
              "      <td>[44, 13, 25121, 2181, 6, 10202, 9]</td>\n",
              "      <td>[18, 9015, 3, 1909, 19, 104, 49, 2555, 8, 2106...</td>\n",
              "      <td>[[11, 8, 20], [20, 5, 9], [24, 3, 9, 3, 21], [...</td>\n",
              "      <td>[[22, 21], [28, 40, 31, 29], [23], [14, 11, 5,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ...                             char_tokenized_context\n",
              "0  572667e6708984140094c4f9  ...  [[5, 17, 4, 3, 10], [8, 24, 3, 10], [5], [13, ...\n",
              "1  56dec2483277331400b4d712  ...  [[9, 14, 11, 20, 5, 10, 39, 3, 7, 3, 19, 19, 3...\n",
              "2  5726e5995951b619008f81bb  ...  [[6, 4], [11, 5, 9], [22, 3, 3, 7], [8, 22, 9,...\n",
              "3  5726486f708984140094c157  ...  [[5, 17, 4, 3, 10], [10, 3, 4, 15, 10, 7, 6, 7...\n",
              "4  5730299db2c2fd14005689a7  ...  [[22, 21], [28, 40, 31, 29], [23], [14, 11, 5,...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqFA9EEZ37cn",
        "outputId": "17e399e1-6517-4565-bc1a-08771284c2c7"
      },
      "source": [
        "print(tr_df2['tokenized_question'].str.len().describe())\r\n",
        "vl_df2['tokenized_question'].str.len().describe()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    69572.000000\n",
            "mean        11.274579\n",
            "std          3.714049\n",
            "min          1.000000\n",
            "25%          9.000000\n",
            "50%         11.000000\n",
            "75%         13.000000\n",
            "max         60.000000\n",
            "Name: tokenized_question, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    17394.000000\n",
              "mean        11.336438\n",
              "std          3.754368\n",
              "min          1.000000\n",
              "25%          9.000000\n",
              "50%         11.000000\n",
              "75%         13.000000\n",
              "max         38.000000\n",
              "Name: tokenized_question, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByaQ8Qhe39d_",
        "outputId": "37f51cc2-4d3e-495e-fdf5-dba3230039e0"
      },
      "source": [
        "print(tr_df2['tokenized_question'].str.len().quantile(0.99))\r\n",
        "vl_df2['tokenized_question'].str.len().quantile(0.99)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmHrHFEL3-jb",
        "outputId": "056b4865-9a0f-47c0-818e-159502322784"
      },
      "source": [
        "print(tr_df2['tokenized_context'].str.len().describe())\r\n",
        "vl_df2['tokenized_context'].str.len().describe()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    69572.000000\n",
            "mean       137.928678\n",
            "std         56.993429\n",
            "min         22.000000\n",
            "25%        102.000000\n",
            "50%        127.000000\n",
            "75%        164.000000\n",
            "max        766.000000\n",
            "Name: tokenized_context, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    17394.000000\n",
              "mean       137.330229\n",
              "std         55.948282\n",
              "min         22.000000\n",
              "25%        102.000000\n",
              "50%        126.000000\n",
              "75%        163.000000\n",
              "max        766.000000\n",
              "Name: tokenized_context, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DolCBxLo3__X",
        "outputId": "94050488-4dc6-4249-bed7-bc212f308b69"
      },
      "source": [
        "print(tr_df2['tokenized_context'].str.len().quantile(0.99))\r\n",
        "vl_df2['tokenized_context'].str.len().quantile(0.99)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "324.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFewuMt4Crd"
      },
      "source": [
        "def len_words(dataset):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  return the word's length\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  count_q = []\r\n",
        "  count_c = []\r\n",
        "\r\n",
        "  for idx, row in dataset.iterrows():\r\n",
        "    for w in row['char_tokenized_question']:\r\n",
        "      l = len(w)\r\n",
        "      count_q.append(l)\r\n",
        "      \r\n",
        "    for w in row['char_tokenized_context']:\r\n",
        "      m = len(w)\r\n",
        "      count_c.append(m)\r\n",
        "  \r\n",
        "  return pd.Series(count_q), pd.Series(count_c)\r\n",
        "\r\n",
        "t_q,t_c = len_words(tr_df2)\r\n",
        "v_q,v_c = len_words(vl_df2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7vqhZt14D8U",
        "outputId": "5cd85af4-3b3b-45a9-a3fb-ca6d9a28558a"
      },
      "source": [
        "print(t_q.describe())\r\n",
        "t_c.describe()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    784395.000000\n",
            "mean          4.447990\n",
            "std           2.677571\n",
            "min           1.000000\n",
            "25%           2.000000\n",
            "50%           4.000000\n",
            "75%           6.000000\n",
            "max          30.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    9.595974e+06\n",
              "mean     4.625712e+00\n",
              "std      2.969451e+00\n",
              "min      1.000000e+00\n",
              "25%      2.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      7.000000e+00\n",
              "max      3.700000e+01\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KGWK3xs4E94",
        "outputId": "e0e95cc9-b3f3-4d2f-c554-aac439282c1d"
      },
      "source": [
        "print(v_q.describe())\r\n",
        "v_c.describe()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    197186.000000\n",
            "mean          4.452943\n",
            "std           2.686307\n",
            "min           1.000000\n",
            "25%           2.000000\n",
            "50%           4.000000\n",
            "75%           6.000000\n",
            "max          24.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.388722e+06\n",
              "mean     4.629325e+00\n",
              "std      2.972493e+00\n",
              "min      1.000000e+00\n",
              "25%      2.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      7.000000e+00\n",
              "max      3.700000e+01\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlyjLbHO4GCQ",
        "outputId": "eca3276d-1bfc-4f6c-f653-bd7595c0d6c8"
      },
      "source": [
        "print(t_q.quantile(0.99))\r\n",
        "t_c.quantile(0.99)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRejHV5E4HOj",
        "outputId": "ff78fad3-5b0c-4766-94d9-3360c07862d4"
      },
      "source": [
        "print(v_q.quantile(0.99))\r\n",
        "v_c.quantile(0.99)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2edXGofT4Hn2"
      },
      "source": [
        "There are obviously some outliers. We are compeled to get rid of some samples because of memory issues.\r\n",
        "\r\n",
        "We will get rid of contexts that have more than 350 characters and questions that have more than 25 words.\r\n",
        "\r\n",
        "We will set the length of a word to 15 characters\r\n",
        "\r\n",
        "**EDIT :** These numbers are huge but we won't get out of memory errors if we build a sequence generator. If you don't want to use the sequence generator, you should reduce these numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdCtXOp34Jj1"
      },
      "source": [
        "QUESTION_MAXLEN = 25\r\n",
        "CONTEXT_MAXLEN = 350\r\n",
        "WORD_MAXLEN = 15\r\n",
        "BATCH_SIZE = 10"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAa1kT3V4L0q",
        "outputId": "a9a158f4-a78e-4c36-91f0-25af7176556b"
      },
      "source": [
        "tr_df2.shape, vl_df2.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((69572, 13), (17394, 13))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb59nAr4NXx"
      },
      "source": [
        "tr_df3 = tr_df2[(tr_df2['tokenized_question'].str.len() <= QUESTION_MAXLEN) & (tr_df2['tokenized_context'].str.len() <= CONTEXT_MAXLEN) & (tr_df2['start'] <= CONTEXT_MAXLEN) & (tr_df2['end'] <= CONTEXT_MAXLEN) ].reset_index(drop = True)\r\n",
        "vl_df3 = vl_df2[(vl_df2['tokenized_question'].str.len() <= QUESTION_MAXLEN) & (vl_df2['tokenized_context'].str.len() <= CONTEXT_MAXLEN) & (vl_df2['start'] <= CONTEXT_MAXLEN) & (vl_df2['end'] <= CONTEXT_MAXLEN) ].reset_index(drop = True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSOmOu3K4OcV",
        "outputId": "e2d15959-ab52-463b-f2e9-8d1d056d7837"
      },
      "source": [
        "tr_df3.shape[0], vl_df3.shape[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68920, 17237)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4If8JsLX4Pp2",
        "outputId": "98177e12-6981-4882-efac-648dde9fbe99"
      },
      "source": [
        " print(f' we get rid of : {SAMPLES - (tr_df3.shape[0] + vl_df3.shape[0])} samples')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " we get rid of : 1442 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwdAOL-94UX1",
        "outputId": "a9d12146-90c0-4bc3-eb26-fccbc44f8643"
      },
      "source": [
        "# save datasets in json format\r\n",
        "path_to_train_set = os.path.join(os.getcwd(), 'BERT_train_set3.json')\r\n",
        "df_to_json(tr_df3, path_to_train_set)\r\n",
        "\r\n",
        "path_to_valid_set = os.path.join(os.getcwd(), 'BERT_valid_set3.json')\r\n",
        "df_to_json(vl_df3, path_to_valid_set)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset saved in /content/BERT_train_set3.json\n",
            "dataset saved in /content/BERT_valid_set3.json\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}